<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure | Research Agent Knowledge Base</title>
<meta name="keywords" content="Stochastic Differential Equations (SDEs), Lévy Processes / Jump Diffusion Models, Tamed Milstein Scheme, Neural Networks (NN) / Non-parametric Estimation, Conditional Moments Inference">
<meta name="description" content="Abstract This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \mathbb{Z} \to \mathbb{R}$, the diffusion coefficient $g: \mathbb{Z} \to \mathbb{R}$.">
<meta name="author" content="">
<link rel="canonical" href="https://hanwo-ol.github.io/Unet_master/posts/neural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure/">
<link crossorigin="anonymous" href="/Unet_master/assets/css/stylesheet.62aa25427797f8efd87301a5b69795dc50df2dbe79a5fba0648cc7bb8dbcd7c9.css" integrity="sha256-YqolQneX&#43;O/YcwGltpeV3FDfLb55pfugZIzHu42818k=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/Unet_master/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js" integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hanwo-ol.github.io/Unet_master/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hanwo-ol.github.io/Unet_master/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hanwo-ol.github.io/Unet_master/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hanwo-ol.github.io/Unet_master/apple-touch-icon.png">
<link rel="mask-icon" href="https://hanwo-ol.github.io/Unet_master/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure" />
<meta property="og:description" content="Abstract This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \mathbb{Z} \to \mathbb{R}$, the diffusion coefficient $g: \mathbb{Z} \to \mathbb{R}$." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hanwo-ol.github.io/Unet_master/posts/neural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-07-06T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-07-06T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure"/>
<meta name="twitter:description" content="Abstract This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \mathbb{Z} \to \mathbb{R}$, the diffusion coefficient $g: \mathbb{Z} \to \mathbb{R}$."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/neural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure",
  "name": "Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure",
  "description": "Abstract This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \\mathbb{Z} \\to \\mathbb{R}$, the diffusion coefficient $g: \\mathbb{Z} \\to \\mathbb{R}$.",
  "keywords": [
    "Stochastic Differential Equations (SDEs)", "Lévy Processes / Jump Diffusion Models", "Tamed Milstein Scheme", "Neural Networks (NN) / Non-parametric Estimation", "Conditional Moments Inference"
  ],
  "articleBody": "Abstract This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \\mathbb{Z} \\to \\mathbb{R}$, the diffusion coefficient $g: \\mathbb{Z} \\to \\mathbb{R}$. The model of interest is given by [ dX(t) = ξ+ f(X(t)), dt + g(X(t)), dW_t + γ\\int_{\\mathbb{Z}} z, N(dt,dz), ] where $W_t$ is a standard Brownian motion, and $N(dt,dz)$ is a Poisson random measure on $(\\mathbb{R}{+} \\times \\mathbb{Z}$, $\\mathcal{B} (\\mathbb{R}{+}) \\otimes \\mathcal{Z}$, $λ( Λ\\otimes v))$, with $λ, γ\u003e 0$, $Λ$ being the Lebesgue measure on $\\mathbb{R}_{+}$, and $v$ a finite measure on the measurable space $(\\mathbb{Z}, \\mathcal{Z})$. Neural networks are used as non-parametric function approximators, enabling the modeling of complex nonlinear dynamics without assuming restrictive functional forms. The proposed methodology constitutes a flexible alternative for inference in systems with state-dependent noise and discontinuities driven by Lévy processes.\nPDF Download Local PDF View | Arxiv Original\n이 논문은 Lévy 과정에 의해 구동되는 가산 대칭 점프 노이즈(Additive Symmetric Jump Noise)를 포함하는 확률 미분 방정식(SDEs)의 표류(drift) 및 확산(diffusion) 함수를 신경망을 사용하여 비모수적으로 추정하는 방법론을 제안합니다.\n1. 요약 (Executive Summary) 연구 목표: 유한 점프 강도(finite jump intensity)를 가진 Lévy 과정에 의해 구동되는 SDE의 표류 함수 $f(X(t))$와 확산 함수 $g(X(t))$를 비모수적으로 추정하는 프레임워크를 개발합니다. 핵심 방법론: 신경망(Neural Networks)을 비모수적 함수 근사기로 활용하고, 이를 Tamed-Milstein 수치 기법과 통합합니다. 모델 형태: 관심 SDE는 다음과 같습니다. $$dX(t) = \\xi + f(X(t))dt + g(X(t))dW + \\int_Z \\gamma z N(dt, dz)$$ 여기서 $W$는 표준 브라운 운동, $N(dt, dz)$는 푸아송 랜덤 측도(Poisson Random Measure)입니다. 훈련 전략: 증분(increments)의 조건부 1차 및 2차 모멘트 최소화에 의존하는 손실 함수를 사용하여 신경망을 훈련합니다. 주요 성과: 제안된 방법론은 상태 의존적 노이즈와 불연속성(점프)을 가진 시스템에 대해 유연한 추론 대안을 제공하며, 수치 실험을 통해 연속 및 점프 구동 환경 모두에서 표류 및 확산 계수를 정확하게 추정함을 입증했습니다. 수치적 우수성: 제안된 알고리즘을 사용했을 때, 표류 및 확산 계수 추정의 최대 평균 제곱 오차(MSE)가 $10^{-3}$ 수준으로 나타나, 높은 정확도를 달성했습니다. 2. 7가지 핵심 질문 분석 (Key Analysis) 1) What is new in the work? (기존 연구와의 차별점) 이 연구는 신경망을 사용하여 점프를 포함하는 SDE의 계수를 추정하는 비모수적 프레임워크를 제안합니다. 기존 연구(예: [11])가 1차 수렴 순서(strong convergence order)를 갖는 Euler-Maruyama 근사를 사용했던 것과 달리, 본 논문은 Tamed-Milstein 수치 기법을 통합하여 더 높은 수렴 순서(점프가 없을 때 $\\kappa=1$)를 달성합니다. 또한, 확산 계수 $g$가 수렴 영역 근처에서 과적합되는 문제를 해결하기 위해, 조건부 분산에 기반한 **선택적 교대 랜덤 훈련 전략(selective alternating random training strategy)**을 도입하여 훈련 데이터셋의 균형 잡힌 표현을 보장합니다.\n2) Why is the work important? (연구의 중요성) SDE는 금융, 생태학, 신경과학 등 불확실성과 노이즈에 의해 구동되는 시스템을 모델링하는 데 필수적입니다. 특히 점프-확산 모델은 자산 가격의 급격한 변화와 같은 불연속적인 현상을 포착할 수 있어 현실적인 모델링에 중요합니다. 전통적인 모수적 접근 방식은 함수 형태에 제한적인 가정을 부과하여 모델 오지정(misspecification)을 초래할 수 있지만, 이 연구에서 제안된 신경망 기반의 비모수적 접근 방식은 복잡한 비선형 동역학을 유연하게 모델링할 수 있게 합니다. Tamed-Milstein의 사용은 수치 근사의 견고성과 정확도를 높여 신뢰할 수 있는 추론을 가능하게 합니다.\n3) What is the literature gap? (기존 연구의 한계점) 기존 연구의 주요 한계점은 두 가지입니다. 첫째, SDE 계수 추정을 위한 전통적인 방법은 함수 형태에 엄격한 구조적 제약을 부과했습니다. 둘째, 신경망을 사용한 기존의 비모수적 추정 프레임워크(예: [11])는 낮은 수렴 순서의 Euler-Maruyama 근사를 사용했습니다. 또한, 특히 궤적이 0으로 수렴하여 변동성이 사라지는 영역에서, 기존의 우도(likelihood) 기반 2단계 추정 절차는 확산 계수 $g$를 과소평가하는 경향이 있었습니다 (Figure 2 분석).\n4) How is the gap filled? (해결 방안) 이 연구는 Tamed-Milstein 수치 기법을 채택하여 SDE 해의 2차 근사를 제공함으로써 수렴 순서 문제를 해결했습니다. 확산 계수 $g$의 과소평가 문제를 해결하기 위해 3단계 알고리즘을 제안했습니다. 이 알고리즘은 조건부 분산(conditional variance)을 기반으로 손실 함수를 정의하고, 높은 손실 값을 가진 브랜치(branch)를 선호하는 선택적 랜덤 훈련을 수행합니다. 특히, 훈련 샘플 선택 시 조건부 분산을 표준화하여(Equation 19), 궤적이 수렴하는 영역 근처에서 확산 계수가 과적합되는 것을 방지하고 훈련 세트의 균질성을 높입니다.\n5) What is achieved with the new method? (달성한 성과) 제안된 방법론은 다양한 시나리오에서 높은 정확도로 $f$와 $g$를 추정했습니다.\n시나리오 (Table I: $\\lambda=0$ 또는 $\\gamma=0$) 표류 계수 $f(X_t)$ 확산 계수 $g(X_t)$ $L_{2,f}$ 오차 $L_{2,g}$ 오차 1 $-0.25X_t^3$ $0.57X_t$ 0.00492 0.00347 2 $0.15(X_t-X_t^5)$ $0.32 \\sin(X_t)$ 0.00292 0.00013 3 $1-X_t$ 1 0.01600 0.00009 시나리오 (Table II: $\\lambda \\neq 0$ 및 $\\gamma \\neq 0$) $(\\gamma, \\lambda)$ 점프 $z_i$ $f(X_t)$ $g(X_t)$ $L_{2,f}$ 오차 $L_{2,g}$ 오차 1 (0.8, 1.2) $U(-0.1, 0.1)$ $1-X_t$ $0.31X_t$ 0.00401 0.00046 2 (0.31, 1.7) $N(0, 0.12)$ $0.28(X_t-X_t^3)$ 1 0.05564 0.00094 3 (1.47, 0.5) $Laplace(0, 0.1)$ $\\cos(X_t)$ 1 0.00675 0.00008 전반적으로, 참 함수와 신경망 추정치 사이의 최대 MSE는 $10^{-2}$ 수준이며, 대부분의 경우 $10^{-3}$ 이하의 높은 정확도를 보였습니다. 특히, Phase 3 알고리즘을 사용했을 때 (Figure 4, Panel B), $f$와 $g$ 모두에 대해 MSE가 $0.0049$와 $0.0034$로 크게 개선되었습니다.\n6) What data are used? (사용 데이터셋) 이 연구는 모두 시뮬레이션된 합성 데이터를 사용합니다.\n데이터 생성: SDE (Equation 7)의 $K=10$개 독립 궤적을 $[0, 5]$ 구간에서 $N=1000$ 시간 단계로 균일하게 이산화하여 시뮬레이션했습니다. 초기 조건은 $X(0)=1.5$로 고정되었습니다. 도메인 특성: 점프 노이즈는 푸아송 랜덤 측도에 의해 구동되는 가산 대칭 점프 노이즈입니다. 점프 크기 $z_i$는 0에 대해 대칭이며 유한 2차 모멘트를 갖는다고 가정합니다. 사용된 점프 분포: 수치 실험에서는 균일 분포 $U(-0.1, 0.1)$, 정규 분포 $N(0, 0.12)$, 라플라스 분포 $Laplace(0, 1)$ 등이 사용되었습니다. 7) What are the limitations? (저자가 언급한 한계점) 저자가 언급한 주요 한계점은 다음과 같습니다.\n비식별성(Non-identifiability): 점프 크기 $z_i$가 스케일링 매개변수 $\\gamma$에 의해 조정될 때, $\\gamma$를 1로 설정하고 점프 값을 $\\gamma z_i$로 대체하는 과정과 구별할 수 없어 $\\gamma$가 비식별적일 수 있습니다. 이를 해결하기 위해 $z_i$를 표준화(평균 0, 단위 분산)해야 합니다. 일반 함수 $\\gamma(x, z)$ 추정의 어려움: 일반적인 상태 의존적 점프 함수 $\\gamma(x, z)$를 추정하려면 점프 분포의 고차 모멘트를 평가해야 할 수 있으며, 이는 모델 가정에 따라 존재하지 않을 수 있습니다. 다차원 시스템 확장: 제안된 방법론을 다차원 SDE로 확장하려면 수치 기법과 신경망 아키텍처 모두에 대한 신중한 조정이 필요합니다. 하이퍼파라미터 선택: 훈련 하이퍼파라미터($R_1, R_2, R_3, R_4, \\text{train}_f$)의 선택은 여전히 개방된 문제이며, 현재는 경험적으로 선택되고 있습니다. 3. 아키텍처 및 방법론 (Architecture \u0026 Methodology) Figure 분석: 아키텍처 구조 논문은 이미지 분할에 주로 사용되는 U-Net 구조를 사용하지 않고, 표류 함수 $f$와 확산 함수 $g$를 근사하기 위해 두 개의 독립적인 **다층 퍼셉트론(MLP) 또는 심층 신경망(DNN)**을 사용합니다.\n표류 함수 $f$를 위한 신경망: 입력층: 선형 입력층. 은닉층: 4개의 은닉층, 각 층은 32개의 뉴런을 가지며 ELU (Exponential Linear Unit) 활성화 함수를 사용합니다. 출력층: 선형 출력층. 확산 함수 $g$를 위한 신경망: 입력층: 선형 입력층. 은닉층: 3개의 은닉층, 각 층은 32개의 뉴런을 가지며 ELU 활성화 함수를 사용합니다. 출력층: Softplus 활성화 함수를 사용하는 출력층. (확산 계수 $g$가 양수 값을 갖도록 보장하기 위함.) 수식 상세 SDE 모델 (Equation 1) 이 연구에서 다루는 SDE는 다음과 같습니다. $$dX(t) = \\xi + f(X(t))dt + g(X(t))dW + \\int_Z \\gamma z N(dt, dz)$$ 여기서 $f: \\mathbb{R} \\to \\mathbb{R}$는 표류 함수, $g: \\mathbb{R} \\to \\mathbb{R}$는 확산 계수, $\\gamma \u003e 0$는 점프 크기 스케일링 매개변수입니다.\nTamed-Milstein 근사 (Equation 7) 시간 간격 $h$에 대한 이산화 근사 $X_{t+\\Delta t}$는 다음과 같습니다. $$\\begin{aligned} X_{t+\\Delta t} = X_t \u0026+ f^{\\Delta t}(X_t) \\Delta t + g(X_t) \\Delta W_t \\ \u0026+ \\frac{1}{2} g(X_t) g’(X_t) ((\\Delta W_t)^2 - \\Delta t) \\ \u0026+ \\sum_{i=1}^{N((t, t+\\Delta t], Z)} \\gamma z_i \\ \u0026+ \\sum_{i=1}^{N((t, t+\\Delta t], Z)} (g(X_t + \\gamma z_i) - g(X_t)) (\\Delta W_{t+\\Delta t} - \\Delta W_{t_i}) \\end{aligned}$$ 여기서 $f^{\\Delta t}(x)$는 테이밍된(tamed) 표류 항으로, 다음과 같이 정의됩니다. $$f^{\\Delta t}(x) = \\frac{f(x)}{1+\\Delta t f^2(x)}$$\n조건부 1차 모멘트 (Conditional Expectation, Equation 8) $$E (X_{t+\\Delta t} | \\mathcal{F}(X_t)) = X_t + f^{\\Delta t}(X_t) \\Delta t$$\n조건부 2차 모멘트 (Conditional Second Moment, Equation 15) 증분의 조건부 분산은 $E(M_1^2 | \\mathcal{F}(X_t)) + E(M_2^2 | \\mathcal{F}(X_t))$로 주어지며, $\\lambda \\neq 0$ 및 $\\gamma \\neq 0$일 때 다음과 같습니다. $$\\begin{aligned} E \\left( (X_{t+\\Delta t} - E(X_{t+\\Delta t} | \\mathcal{F}(X_t)))^2 | \\mathcal{F}(X_t) \\right) \u0026= g^2(X_t)\\Delta t + \\frac{1}{4} (g(X_t)g’(X_t)\\Delta t)^2 \\ \u0026+ \\gamma^2 \\mu_2 \\lambda \\Delta t + \\text{higher order jump terms} \\end{aligned}$$ 여기서 $\\mu_2 = E[z^2]$는 점프 크기의 2차 모멘트입니다.\n표류 함수 손실 $D_1$ (Loss Function for Drift, Equation 11) Phase 1에서 표류 함수 $\\hat{f}$를 추정하기 위해 사용되는 평균 제곱 오차(MSE) 손실 함수입니다. $$D_1(\\hat{f}, \\hat{g}, B_k, j) := \\frac{1}{|B_k|-1} \\sum_{t_i \\in B_k \\setminus {t_{k, |B_k|}}} \\left[ X_{j, t_{i+1}} - X_{j, t_i} - \\hat{f}^{\\Delta t}(X_{j, t_i}) \\Delta t_{i+1} \\right]^2$$\n확산 함수 손실 $D_2$ (Loss Function for Diffusion, Equation 12) Phase 1에서 확산 함수 $\\hat{g}$를 추정하기 위해 사용되는 근사 우도(likelihood) 손실 함수입니다. $$D_2(\\hat{f}, \\hat{g}, B_k, j) := - \\sum_{t_i \\in B_k \\setminus {t_{k, |B_k|}}} \\log f_{t_i, \\Delta t_i}^{M, h, a} (X_{j, t_{i+1}} | X_{j, t_i})$$ 여기서 $f^{M, h, a}$는 특성 함수(Characteristic Function)를 이용해 근사된 조건부 밀도 함수입니다.\n표준화된 조건부 증분 $Y_{t, \\Delta t}^*$ (Equation 19, $\\gamma=0$일 때) Phase 3에서 선택적 훈련을 위해 사용되는 표준화된 조건부 증분입니다. $$Y_{t, \\Delta t}^* := \\frac{X_{t+\\Delta t} - (X_t + \\hat{f}^{\\Delta t}(X_t)\\Delta t)}{\\sqrt{g^2(X_t)\\Delta t + \\frac{1}{4} (g(X_t)g’(X_t)\\Delta t)^2}}$$\nVanilla U-Net 비교 이 논문에서 사용된 아키텍처는 U-Net 구조가 아닙니다.\n특징 Vanilla U-Net 본 논문의 아키텍처 (MLP/DNN) 목적 이미지 분할, 시퀀스-투-시퀀스 매핑 SDE 계수 $f(X)$ 및 $g(X)$의 비모수적 함수 근사 구조 인코더-디코더 구조, 스킵 커넥션 사용 표준 다층 퍼셉트론 (MLP) 입력/출력 이미지/텐서 (고차원) SDE 상태 $X_t$ (1차원 실수) / $f(X_t)$ 또는 $g(X_t)$ (1차원 실수) 주요 모듈 컨볼루션, 풀링, 업샘플링 선형층, ELU/Softplus 활성화 함수 변경/추가된 모듈 해당 없음 확산 계수 $g$의 출력층에 Softplus를 사용하여 양수 값 보장 4. 태그 제안 (Tags Suggestion) Stochastic Differential Equations (SDEs) Lévy Processes / Jump Diffusion Models Tamed Milstein Scheme Neural Networks (NN) / Non-parametric Estimation Conditional Moments Inference ",
  "wordCount" : "1537",
  "inLanguage": "en",
  "datePublished": "2025-07-06T00:00:00Z",
  "dateModified": "2025-07-06T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hanwo-ol.github.io/Unet_master/posts/neural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Research Agent Knowledge Base",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hanwo-ol.github.io/Unet_master/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hanwo-ol.github.io/Unet_master/" accesskey="h" title="Research Agent Knowledge Base (Alt + H)">Research Agent Knowledge Base</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hanwo-ol.github.io/Unet_master/">Home</a>&nbsp;»&nbsp;<a href="https://hanwo-ol.github.io/Unet_master/posts/">Posts</a></div>
    <h1 class="post-title">
      Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure
    </h1>
    <div class="post-meta">&lt;span title=&#39;2025-07-06 00:00:00 &#43;0000 UTC&#39;&gt;July 6, 2025&lt;/span&gt;&amp;nbsp;·&amp;nbsp;8 min

</div>
  </header> 
  <div class="post-content"><h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>This work aims to estimate the drift and diffusion functions in stochastic differential equations (SDEs) driven by a particular class of Lévy processes with finite jump intensity, using neural networks. We propose a framework that integrates the Tamed-Milstein scheme with neural networks employed as non-parametric function approximators. Estimation is carried out in a non-parametric fashion for the drift function $f: \mathbb{Z} \to \mathbb{R}$, the diffusion coefficient $g: \mathbb{Z} \to \mathbb{R}$. The model of interest is given by [ dX(t) = ξ+ f(X(t)), dt + g(X(t)), dW_t + γ\int_{\mathbb{Z}} z, N(dt,dz), ] where $W_t$ is a standard Brownian motion, and $N(dt,dz)$ is a Poisson random measure on $(\mathbb{R}<em>{+} \times \mathbb{Z}$, $\mathcal{B} (\mathbb{R}</em>{+}) \otimes \mathcal{Z}$, $λ( Λ\otimes v))$, with $λ, γ&gt; 0$, $Λ$ being the Lebesgue measure on $\mathbb{R}_{+}$, and $v$ a finite measure on the measurable space $(\mathbb{Z}, \mathcal{Z})$. Neural networks are used as non-parametric function approximators, enabling the modeling of complex nonlinear dynamics without assuming restrictive functional forms. The proposed methodology constitutes a flexible alternative for inference in systems with state-dependent noise and discontinuities driven by Lévy processes.</p>
<h2 id="pdf-download">PDF Download<a hidden class="anchor" aria-hidden="true" href="#pdf-download">#</a></h2>
<p><a href="//172.22.138.185/Research_pdf/2507.04417v2.pdf">Local PDF View</a> | <a href="http://arxiv.org/abs/2507.04417v2">Arxiv Original</a></p>
<p>이 논문은 Lévy 과정에 의해 구동되는 가산 대칭 점프 노이즈(Additive Symmetric Jump Noise)를 포함하는 확률 미분 방정식(SDEs)의 표류(drift) 및 확산(diffusion) 함수를 신경망을 사용하여 비모수적으로 추정하는 방법론을 제안합니다.</p>
<hr>
<h2 id="1-요약-executive-summary">1. 요약 (Executive Summary)<a hidden class="anchor" aria-hidden="true" href="#1-요약-executive-summary">#</a></h2>
<ul>
<li><strong>연구 목표:</strong> 유한 점프 강도(finite jump intensity)를 가진 Lévy 과정에 의해 구동되는 SDE의 표류 함수 $f(X(t))$와 확산 함수 $g(X(t))$를 비모수적으로 추정하는 프레임워크를 개발합니다.</li>
<li><strong>핵심 방법론:</strong> 신경망(Neural Networks)을 비모수적 함수 근사기로 활용하고, 이를 <strong>Tamed-Milstein 수치 기법</strong>과 통합합니다.</li>
<li><strong>모델 형태:</strong> 관심 SDE는 다음과 같습니다.
$$dX(t) = \xi + f(X(t))dt + g(X(t))dW + \int_Z \gamma z N(dt, dz)$$
여기서 $W$는 표준 브라운 운동, $N(dt, dz)$는 푸아송 랜덤 측도(Poisson Random Measure)입니다.</li>
<li><strong>훈련 전략:</strong> 증분(increments)의 조건부 1차 및 2차 모멘트 최소화에 의존하는 손실 함수를 사용하여 신경망을 훈련합니다.</li>
<li><strong>주요 성과:</strong> 제안된 방법론은 상태 의존적 노이즈와 불연속성(점프)을 가진 시스템에 대해 유연한 추론 대안을 제공하며, 수치 실험을 통해 연속 및 점프 구동 환경 모두에서 표류 및 확산 계수를 정확하게 추정함을 입증했습니다.</li>
<li><strong>수치적 우수성:</strong> 제안된 알고리즘을 사용했을 때, 표류 및 확산 계수 추정의 최대 평균 제곱 오차(MSE)가 $10^{-3}$ 수준으로 나타나, 높은 정확도를 달성했습니다.</li>
</ul>
<hr>
<h2 id="2-7가지-핵심-질문-분석-key-analysis">2. 7가지 핵심 질문 분석 (Key Analysis)<a hidden class="anchor" aria-hidden="true" href="#2-7가지-핵심-질문-분석-key-analysis">#</a></h2>
<h3 id="1-what-is-new-in-the-work-기존-연구와의-차별점">1) What is new in the work? (기존 연구와의 차별점)<a hidden class="anchor" aria-hidden="true" href="#1-what-is-new-in-the-work-기존-연구와의-차별점">#</a></h3>
<p>이 연구는 신경망을 사용하여 점프를 포함하는 SDE의 계수를 추정하는 비모수적 프레임워크를 제안합니다. 기존 연구(예: [11])가 1차 수렴 순서(strong convergence order)를 갖는 Euler-Maruyama 근사를 사용했던 것과 달리, 본 논문은 <strong>Tamed-Milstein 수치 기법</strong>을 통합하여 더 높은 수렴 순서(점프가 없을 때 $\kappa=1$)를 달성합니다. 또한, 확산 계수 $g$가 수렴 영역 근처에서 과적합되는 문제를 해결하기 위해, 조건부 분산에 기반한 **선택적 교대 랜덤 훈련 전략(selective alternating random training strategy)**을 도입하여 훈련 데이터셋의 균형 잡힌 표현을 보장합니다.</p>
<h3 id="2-why-is-the-work-important-연구의-중요성">2) Why is the work important? (연구의 중요성)<a hidden class="anchor" aria-hidden="true" href="#2-why-is-the-work-important-연구의-중요성">#</a></h3>
<p>SDE는 금융, 생태학, 신경과학 등 불확실성과 노이즈에 의해 구동되는 시스템을 모델링하는 데 필수적입니다. 특히 점프-확산 모델은 자산 가격의 급격한 변화와 같은 불연속적인 현상을 포착할 수 있어 현실적인 모델링에 중요합니다. 전통적인 모수적 접근 방식은 함수 형태에 제한적인 가정을 부과하여 모델 오지정(misspecification)을 초래할 수 있지만, 이 연구에서 제안된 신경망 기반의 비모수적 접근 방식은 복잡한 비선형 동역학을 유연하게 모델링할 수 있게 합니다. Tamed-Milstein의 사용은 수치 근사의 견고성과 정확도를 높여 신뢰할 수 있는 추론을 가능하게 합니다.</p>
<h3 id="3-what-is-the-literature-gap-기존-연구의-한계점">3) What is the literature gap? (기존 연구의 한계점)<a hidden class="anchor" aria-hidden="true" href="#3-what-is-the-literature-gap-기존-연구의-한계점">#</a></h3>
<p>기존 연구의 주요 한계점은 두 가지입니다. 첫째, SDE 계수 추정을 위한 전통적인 방법은 함수 형태에 엄격한 구조적 제약을 부과했습니다. 둘째, 신경망을 사용한 기존의 비모수적 추정 프레임워크(예: [11])는 낮은 수렴 순서의 Euler-Maruyama 근사를 사용했습니다. 또한, 특히 궤적이 0으로 수렴하여 변동성이 사라지는 영역에서, 기존의 우도(likelihood) 기반 2단계 추정 절차는 확산 계수 $g$를 과소평가하는 경향이 있었습니다 (Figure 2 분석).</p>
<h3 id="4-how-is-the-gap-filled-해결-방안">4) How is the gap filled? (해결 방안)<a hidden class="anchor" aria-hidden="true" href="#4-how-is-the-gap-filled-해결-방안">#</a></h3>
<p>이 연구는 Tamed-Milstein 수치 기법을 채택하여 SDE 해의 2차 근사를 제공함으로써 수렴 순서 문제를 해결했습니다. 확산 계수 $g$의 과소평가 문제를 해결하기 위해 <strong>3단계 알고리즘</strong>을 제안했습니다. 이 알고리즘은 조건부 분산(conditional variance)을 기반으로 손실 함수를 정의하고, 높은 손실 값을 가진 브랜치(branch)를 선호하는 <strong>선택적 랜덤 훈련</strong>을 수행합니다. 특히, 훈련 샘플 선택 시 조건부 분산을 표준화하여(Equation 19), 궤적이 수렴하는 영역 근처에서 확산 계수가 과적합되는 것을 방지하고 훈련 세트의 균질성을 높입니다.</p>
<h3 id="5-what-is-achieved-with-the-new-method-달성한-성과">5) What is achieved with the new method? (달성한 성과)<a hidden class="anchor" aria-hidden="true" href="#5-what-is-achieved-with-the-new-method-달성한-성과">#</a></h3>
<p>제안된 방법론은 다양한 시나리오에서 높은 정확도로 $f$와 $g$를 추정했습니다.</p>
<table>
<thead>
<tr>
<th style="text-align:left">시나리오 (Table I: $\lambda=0$ 또는 $\gamma=0$)</th>
<th style="text-align:left">표류 계수 $f(X_t)$</th>
<th style="text-align:left">확산 계수 $g(X_t)$</th>
<th style="text-align:left">$L_{2,f}$ 오차</th>
<th style="text-align:left">$L_{2,g}$ 오차</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">$-0.25X_t^3$</td>
<td style="text-align:left">$0.57X_t$</td>
<td style="text-align:left">0.00492</td>
<td style="text-align:left">0.00347</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">$0.15(X_t-X_t^5)$</td>
<td style="text-align:left">$0.32 \sin(X_t)$</td>
<td style="text-align:left">0.00292</td>
<td style="text-align:left">0.00013</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">$1-X_t$</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0.01600</td>
<td style="text-align:left">0.00009</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">시나리오 (Table II: $\lambda \neq 0$ 및 $\gamma \neq 0$)</th>
<th style="text-align:left">$(\gamma, \lambda)$</th>
<th style="text-align:left">점프 $z_i$</th>
<th style="text-align:left">$f(X_t)$</th>
<th style="text-align:left">$g(X_t)$</th>
<th style="text-align:left">$L_{2,f}$ 오차</th>
<th style="text-align:left">$L_{2,g}$ 오차</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">1</td>
<td style="text-align:left">(0.8, 1.2)</td>
<td style="text-align:left">$U(-0.1, 0.1)$</td>
<td style="text-align:left">$1-X_t$</td>
<td style="text-align:left">$0.31X_t$</td>
<td style="text-align:left">0.00401</td>
<td style="text-align:left">0.00046</td>
</tr>
<tr>
<td style="text-align:left">2</td>
<td style="text-align:left">(0.31, 1.7)</td>
<td style="text-align:left">$N(0, 0.12)$</td>
<td style="text-align:left">$0.28(X_t-X_t^3)$</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0.05564</td>
<td style="text-align:left">0.00094</td>
</tr>
<tr>
<td style="text-align:left">3</td>
<td style="text-align:left">(1.47, 0.5)</td>
<td style="text-align:left">$Laplace(0, 0.1)$</td>
<td style="text-align:left">$\cos(X_t)$</td>
<td style="text-align:left">1</td>
<td style="text-align:left">0.00675</td>
<td style="text-align:left">0.00008</td>
</tr>
</tbody>
</table>
<p>전반적으로, 참 함수와 신경망 추정치 사이의 최대 MSE는 $10^{-2}$ 수준이며, 대부분의 경우 $10^{-3}$ 이하의 높은 정확도를 보였습니다. 특히, Phase 3 알고리즘을 사용했을 때 (Figure 4, Panel B), $f$와 $g$ 모두에 대해 MSE가 $0.0049$와 $0.0034$로 크게 개선되었습니다.</p>
<h3 id="6-what-data-are-used-사용-데이터셋">6) What data are used? (사용 데이터셋)<a hidden class="anchor" aria-hidden="true" href="#6-what-data-are-used-사용-데이터셋">#</a></h3>
<p>이 연구는 모두 <strong>시뮬레이션된 합성 데이터</strong>를 사용합니다.</p>
<ul>
<li><strong>데이터 생성:</strong> SDE (Equation 7)의 $K=10$개 독립 궤적을 $[0, 5]$ 구간에서 $N=1000$ 시간 단계로 균일하게 이산화하여 시뮬레이션했습니다. 초기 조건은 $X(0)=1.5$로 고정되었습니다.</li>
<li><strong>도메인 특성:</strong> 점프 노이즈는 푸아송 랜덤 측도에 의해 구동되는 가산 대칭 점프 노이즈입니다. 점프 크기 $z_i$는 0에 대해 대칭이며 유한 2차 모멘트를 갖는다고 가정합니다.</li>
<li><strong>사용된 점프 분포:</strong> 수치 실험에서는 균일 분포 $U(-0.1, 0.1)$, 정규 분포 $N(0, 0.12)$, 라플라스 분포 $Laplace(0, 1)$ 등이 사용되었습니다.</li>
</ul>
<h3 id="7-what-are-the-limitations-저자가-언급한-한계점">7) What are the limitations? (저자가 언급한 한계점)<a hidden class="anchor" aria-hidden="true" href="#7-what-are-the-limitations-저자가-언급한-한계점">#</a></h3>
<p>저자가 언급한 주요 한계점은 다음과 같습니다.</p>
<ol>
<li><strong>비식별성(Non-identifiability):</strong> 점프 크기 $z_i$가 스케일링 매개변수 $\gamma$에 의해 조정될 때, $\gamma$를 1로 설정하고 점프 값을 $\gamma z_i$로 대체하는 과정과 구별할 수 없어 $\gamma$가 비식별적일 수 있습니다. 이를 해결하기 위해 $z_i$를 표준화(평균 0, 단위 분산)해야 합니다.</li>
<li><strong>일반 함수 $\gamma(x, z)$ 추정의 어려움:</strong> 일반적인 상태 의존적 점프 함수 $\gamma(x, z)$를 추정하려면 점프 분포의 고차 모멘트를 평가해야 할 수 있으며, 이는 모델 가정에 따라 존재하지 않을 수 있습니다.</li>
<li><strong>다차원 시스템 확장:</strong> 제안된 방법론을 다차원 SDE로 확장하려면 수치 기법과 신경망 아키텍처 모두에 대한 신중한 조정이 필요합니다.</li>
<li><strong>하이퍼파라미터 선택:</strong> 훈련 하이퍼파라미터($R_1, R_2, R_3, R_4, \text{train}_f$)의 선택은 여전히 개방된 문제이며, 현재는 경험적으로 선택되고 있습니다.</li>
</ol>
<hr>
<h2 id="3-아키텍처-및-방법론-architecture--methodology">3. 아키텍처 및 방법론 (Architecture &amp; Methodology)<a hidden class="anchor" aria-hidden="true" href="#3-아키텍처-및-방법론-architecture--methodology">#</a></h2>
<h3 id="figure-분석-아키텍처-구조">Figure 분석: 아키텍처 구조<a hidden class="anchor" aria-hidden="true" href="#figure-분석-아키텍처-구조">#</a></h3>
<p>논문은 이미지 분할에 주로 사용되는 U-Net 구조를 사용하지 않고, 표류 함수 $f$와 확산 함수 $g$를 근사하기 위해 두 개의 독립적인 **다층 퍼셉트론(MLP) 또는 심층 신경망(DNN)**을 사용합니다.</p>
<ul>
<li><strong>표류 함수 $f$를 위한 신경망:</strong>
<ul>
<li>입력층: 선형 입력층.</li>
<li>은닉층: 4개의 은닉층, 각 층은 32개의 뉴런을 가지며 <strong>ELU (Exponential Linear Unit)</strong> 활성화 함수를 사용합니다.</li>
<li>출력층: 선형 출력층.</li>
</ul>
</li>
<li><strong>확산 함수 $g$를 위한 신경망:</strong>
<ul>
<li>입력층: 선형 입력층.</li>
<li>은닉층: 3개의 은닉층, 각 층은 32개의 뉴런을 가지며 <strong>ELU</strong> 활성화 함수를 사용합니다.</li>
<li>출력층: <strong>Softplus</strong> 활성화 함수를 사용하는 출력층. (확산 계수 $g$가 양수 값을 갖도록 보장하기 위함.)</li>
</ul>
</li>
</ul>
<h3 id="수식-상세">수식 상세<a hidden class="anchor" aria-hidden="true" href="#수식-상세">#</a></h3>
<h4 id="sde-모델-equation-1">SDE 모델 (Equation 1)<a hidden class="anchor" aria-hidden="true" href="#sde-모델-equation-1">#</a></h4>
<p>이 연구에서 다루는 SDE는 다음과 같습니다.
$$dX(t) = \xi + f(X(t))dt + g(X(t))dW + \int_Z \gamma z N(dt, dz)$$
여기서 $f: \mathbb{R} \to \mathbb{R}$는 표류 함수, $g: \mathbb{R} \to \mathbb{R}$는 확산 계수, $\gamma &gt; 0$는 점프 크기 스케일링 매개변수입니다.</p>
<h4 id="tamed-milstein-근사-equation-7">Tamed-Milstein 근사 (Equation 7)<a hidden class="anchor" aria-hidden="true" href="#tamed-milstein-근사-equation-7">#</a></h4>
<p>시간 간격 $h$에 대한 이산화 근사 $X_{t+\Delta t}$는 다음과 같습니다.
$$\begin{aligned} X_{t+\Delta t} = X_t &amp;+ f^{\Delta t}(X_t) \Delta t + g(X_t) \Delta W_t \ &amp;+ \frac{1}{2} g(X_t) g&rsquo;(X_t) ((\Delta W_t)^2 - \Delta t) \ &amp;+ \sum_{i=1}^{N((t, t+\Delta t], Z)} \gamma z_i \ &amp;+ \sum_{i=1}^{N((t, t+\Delta t], Z)} (g(X_t + \gamma z_i) - g(X_t)) (\Delta W_{t+\Delta t} - \Delta W_{t_i}) \end{aligned}$$
여기서 $f^{\Delta t}(x)$는 테이밍된(tamed) 표류 항으로, 다음과 같이 정의됩니다.
$$f^{\Delta t}(x) = \frac{f(x)}{1+\Delta t f^2(x)}$$</p>
<h4 id="조건부-1차-모멘트-conditional-expectation-equation-8">조건부 1차 모멘트 (Conditional Expectation, Equation 8)<a hidden class="anchor" aria-hidden="true" href="#조건부-1차-모멘트-conditional-expectation-equation-8">#</a></h4>
<p>$$E (X_{t+\Delta t} | \mathcal{F}(X_t)) = X_t + f^{\Delta t}(X_t) \Delta t$$</p>
<h4 id="조건부-2차-모멘트-conditional-second-moment-equation-15">조건부 2차 모멘트 (Conditional Second Moment, Equation 15)<a hidden class="anchor" aria-hidden="true" href="#조건부-2차-모멘트-conditional-second-moment-equation-15">#</a></h4>
<p>증분의 조건부 분산은 $E(M_1^2 | \mathcal{F}(X_t)) + E(M_2^2 | \mathcal{F}(X_t))$로 주어지며, $\lambda \neq 0$ 및 $\gamma \neq 0$일 때 다음과 같습니다.
$$\begin{aligned} E \left( (X_{t+\Delta t} - E(X_{t+\Delta t} | \mathcal{F}(X_t)))^2 | \mathcal{F}(X_t) \right) &amp;= g^2(X_t)\Delta t + \frac{1}{4} (g(X_t)g&rsquo;(X_t)\Delta t)^2 \ &amp;+ \gamma^2 \mu_2 \lambda \Delta t + \text{higher order jump terms} \end{aligned}$$
여기서 $\mu_2 = E[z^2]$는 점프 크기의 2차 모멘트입니다.</p>
<h4 id="표류-함수-손실-d_1-loss-function-for-drift-equation-11">표류 함수 손실 $D_1$ (Loss Function for Drift, Equation 11)<a hidden class="anchor" aria-hidden="true" href="#표류-함수-손실-d_1-loss-function-for-drift-equation-11">#</a></h4>
<p>Phase 1에서 표류 함수 $\hat{f}$를 추정하기 위해 사용되는 평균 제곱 오차(MSE) 손실 함수입니다.
$$D_1(\hat{f}, \hat{g}, B_k, j) := \frac{1}{|B_k|-1} \sum_{t_i \in B_k \setminus {t_{k, |B_k|}}} \left[ X_{j, t_{i+1}} - X_{j, t_i} - \hat{f}^{\Delta t}(X_{j, t_i}) \Delta t_{i+1} \right]^2$$</p>
<h4 id="확산-함수-손실-d_2-loss-function-for-diffusion-equation-12">확산 함수 손실 $D_2$ (Loss Function for Diffusion, Equation 12)<a hidden class="anchor" aria-hidden="true" href="#확산-함수-손실-d_2-loss-function-for-diffusion-equation-12">#</a></h4>
<p>Phase 1에서 확산 함수 $\hat{g}$를 추정하기 위해 사용되는 근사 우도(likelihood) 손실 함수입니다.
$$D_2(\hat{f}, \hat{g}, B_k, j) := - \sum_{t_i \in B_k \setminus {t_{k, |B_k|}}} \log f_{t_i, \Delta t_i}^{M, h, a} (X_{j, t_{i+1}} | X_{j, t_i})$$
여기서 $f^{M, h, a}$는 특성 함수(Characteristic Function)를 이용해 근사된 조건부 밀도 함수입니다.</p>
<h4 id="표준화된-조건부-증분-y_t-delta-t-equation-19-gamma0일-때">표준화된 조건부 증분 $Y_{t, \Delta t}^*$ (Equation 19, $\gamma=0$일 때)<a hidden class="anchor" aria-hidden="true" href="#표준화된-조건부-증분-y_t-delta-t-equation-19-gamma0일-때">#</a></h4>
<p>Phase 3에서 선택적 훈련을 위해 사용되는 표준화된 조건부 증분입니다.
$$Y_{t, \Delta t}^* := \frac{X_{t+\Delta t} - (X_t + \hat{f}^{\Delta t}(X_t)\Delta t)}{\sqrt{g^2(X_t)\Delta t + \frac{1}{4} (g(X_t)g&rsquo;(X_t)\Delta t)^2}}$$</p>
<h3 id="vanilla-u-net-비교">Vanilla U-Net 비교<a hidden class="anchor" aria-hidden="true" href="#vanilla-u-net-비교">#</a></h3>
<p>이 논문에서 사용된 아키텍처는 <strong>U-Net 구조가 아닙니다.</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">특징</th>
<th style="text-align:left">Vanilla U-Net</th>
<th style="text-align:left">본 논문의 아키텍처 (MLP/DNN)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>목적</strong></td>
<td style="text-align:left">이미지 분할, 시퀀스-투-시퀀스 매핑</td>
<td style="text-align:left">SDE 계수 $f(X)$ 및 $g(X)$의 비모수적 함수 근사</td>
</tr>
<tr>
<td style="text-align:left"><strong>구조</strong></td>
<td style="text-align:left">인코더-디코더 구조, 스킵 커넥션 사용</td>
<td style="text-align:left">표준 다층 퍼셉트론 (MLP)</td>
</tr>
<tr>
<td style="text-align:left"><strong>입력/출력</strong></td>
<td style="text-align:left">이미지/텐서 (고차원)</td>
<td style="text-align:left">SDE 상태 $X_t$ (1차원 실수) / $f(X_t)$ 또는 $g(X_t)$ (1차원 실수)</td>
</tr>
<tr>
<td style="text-align:left"><strong>주요 모듈</strong></td>
<td style="text-align:left">컨볼루션, 풀링, 업샘플링</td>
<td style="text-align:left">선형층, ELU/Softplus 활성화 함수</td>
</tr>
<tr>
<td style="text-align:left"><strong>변경/추가된 모듈</strong></td>
<td style="text-align:left">해당 없음</td>
<td style="text-align:left">확산 계수 $g$의 출력층에 <strong>Softplus</strong>를 사용하여 양수 값 보장</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="4-태그-제안-tags-suggestion">4. 태그 제안 (Tags Suggestion)<a hidden class="anchor" aria-hidden="true" href="#4-태그-제안-tags-suggestion">#</a></h2>
<ol>
<li>Stochastic Differential Equations (SDEs)</li>
<li>Lévy Processes / Jump Diffusion Models</li>
<li>Tamed Milstein Scheme</li>
<li>Neural Networks (NN) / Non-parametric Estimation</li>
<li>Conditional Moments Inference</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/stochastic-differential-equations-sdes/">Stochastic Differential Equations (SDEs)</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/l%C3%A9vy-processes-/-jump-diffusion-models/">Lévy Processes / Jump Diffusion Models</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/tamed-milstein-scheme/">Tamed Milstein Scheme</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/neural-networks-nn-/-non-parametric-estimation/">Neural Networks (NN) / Non-parametric Estimation</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/conditional-moments-inference/">Conditional Moments Inference</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hanwo-ol.github.io/Unet_master/posts/targeted-manipulation-slope-based-attacks-on-financial-time-series-data/">
    <span class="title">« Prev</span>
    <br>
    <span>Targeted Manipulation: Slope-Based Attacks on Financial Time-Series Data</span>
  </a>
  <a class="next" href="https://hanwo-ol.github.io/Unet_master/posts/fast-likelihood-free-parameter-estimation-for-lvy-processes/">
    <span class="title">Next »</span>
    <br>
    <span>Fast Likelihood-Free Parameter Estimation for Lévy Processes</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on twitter"
        href="https://twitter.com/intent/tweet/?text=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f&amp;hashtags=StochasticDifferentialEquations%28SDEs%29%2cL%c3%a9vyProcesses%2fJumpDiffusionModels%2cTamedMilsteinScheme%2cNeuralNetworks%28NN%29%2fNon-parametricEstimation%2cConditionalMomentsInference">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f&amp;title=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure&amp;summary=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure&amp;source=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f&title=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on whatsapp"
        href="https://api.whatsapp.com/send?text=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure%20-%20https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure on telegram"
        href="https://telegram.me/share/url?text=Neural%20Networks%20for%20Tamed%20Milstein%20Approximation%20of%20SDEs%20with%20Additive%20Symmetric%20Jump%20Noise%20Driven%20by%20a%20Poisson%20Random%20Measure&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fneural-networks-for-tamed-milstein-approximation-of-sdes-with-additive-symmetric-jump-noise-driven-by-a-poisson-random-measure%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://hanwo-ol.github.io/Unet_master/">Research Agent Knowledge Base</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
