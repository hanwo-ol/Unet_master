<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models | Research Agent Knowledge Base</title>
<meta name="keywords" content="Auto-Generated, Draft">
<meta name="description" content="Abstract We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA&rsquo;s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km).">
<meta name="author" content="">
<link rel="canonical" href="https://hanwo-ol.github.io/Unet_master/posts/spatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models/">
<link crossorigin="anonymous" href="/Unet_master/assets/css/stylesheet.62aa25427797f8efd87301a5b69795dc50df2dbe79a5fba0648cc7bb8dbcd7c9.css" integrity="sha256-YqolQneX&#43;O/YcwGltpeV3FDfLb55pfugZIzHu42818k=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/Unet_master/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js" integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hanwo-ol.github.io/Unet_master/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hanwo-ol.github.io/Unet_master/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hanwo-ol.github.io/Unet_master/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hanwo-ol.github.io/Unet_master/apple-touch-icon.png">
<link rel="mask-icon" href="https://hanwo-ol.github.io/Unet_master/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models" />
<meta property="og:description" content="Abstract We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA&rsquo;s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hanwo-ol.github.io/Unet_master/posts/spatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-12-01T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-12-01T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models"/>
<meta name="twitter:description" content="Abstract We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA&rsquo;s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km)."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/spatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models",
  "name": "Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models",
  "description": "Abstract We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA\u0026rsquo;s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km).",
  "keywords": [
    "Auto-Generated", "Draft"
  ],
  "articleBody": "Abstract We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA’s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km). Our study area included a large area in Asia, which was made computationally tractable by splitting into two subregions and four seasons. We conducted domain similarity analysis using Wasserstein distances confirmed minimal distributional shift between MERRA-2 and G5NR, validating the safety of parameter frozen transfer. Across seasonal regional splits, our model achieved excellent performance (R2 = 0.65 to 0.94), outperforming comparison models including deterministic U-Nets, variational autoencoders, and prior transfer learning baselines. Out of data evaluations using semivariograms, ACF/PACF, and lag-based RMSE/R2 demonstrated that the predicted downscaled images preserved physically consistent spatial variability and temporal autocorrelation, enabling stable autoregressive reconstruction beyond the G5NR record. These results show that transfer enhanced diffusion models provide a robust and physically coherent solution for downscaling a long time series of coarse resolution images with limited training periods. This advancement has significant implications for improving environmental exposure assessment and long term environmental monitoring.\nPDF Download PDF Download Local PDF View | Arxiv Original\nResearch Agent - Draft Refiner Module 상세 리포트 1. 요약 (Executive Summary) 본 논문은 조악한 해상도의 위성 이미지로부터 미세 해상도의 이미지를 재구성하기 위한 전이 학습 기반의 생성적 다운스케일링 프레임워크를 제안합니다. 이 프레임워크는 장기간의 환경 모니터링 및 노출 평가 개선에 중요한 기여를 합니다.\n프레임워크 구성: 경량 시간적 U-Net 전이 인코더와 확산 기반 생성 모델(Denoising Diffusion Probabilistic Model, DDPM)을 결합하여 20년 기간 동안 일별 미세 해상도 다운스케일링 이미지를 생성합니다. 전이 학습 전략: 단순한 U-Net을 장기간의 저해상도 데이터(MERRA-2)로 사전 학습하여 시공간적 표현을 학습합니다. 이후 이 U-Net의 인코더 가중치를 고정(frozen)하고, 이를 물리적으로 의미 있는 잠재 특징으로 추출하여 더 큰 다운스케일링 모델(DDPM)에 전이합니다. 데이터셋: 저해상도 소스 도메인으로 NASA의 MERRA-2 재분석 데이터(~50 km 해상도)를, 고해상도 타겟 도메인으로 GEOS-5 Nature Run (G5NR) 데이터(~7 km 해상도)의 먼지 소광 AOD(Aerosol Optical Depth)를 사용합니다. 성능 및 안정성: 결정론적 U-Net, 변이형 오토인코더(VAE) 등 비교 모델 대비 우수한 성능(R2 0.65~0.94)을 달성했습니다. Wasserstein Distance 분석을 통해 MERRA-2와 G5NR 간의 최소한의 분포적 차이(minimal distributional shift)를 확인하여 전이 학습의 안전성을 검증했습니다. 물리적 일관성: Semivariogram, ACF/PACF 분석을 통해 예측된 다운스케일링 이미지가 물리적으로 일관된 공간적 변동성과 시간적 자기상관성을 보존하며, G5NR 기록 기간을 넘어선 안정적인 자기회귀적 재구성을 가능하게 함을 입증했습니다. 2. 7가지 핵심 질문 분석 (Key Analysis) 1) What is new in the work? (기존 연구와의 차별점) 본 연구는 전이 학습 인코더와 자기회귀적 생성 모델(DDPM)을 결합한 2단계 다운스케일링 프레임워크를 제안한 것이 가장 큰 차별점입니다. 기존 연구들이 결정론적 U-Net이나 불안정한 GAN/VAE를 사용했던 것과 달리, 본 모델은 장기간의 저해상도 데이터(MERRA-2)에서 학습된 강력한 시공간적 표현을 고정된 인코더를 통해 추출하여, 고해상도 생성 모델(DDPM)에 입력으로 제공합니다. 또한, 이미지 재구성 시 블록 현상 및 에지 효과를 제거하기 위해 Halo-and-Hann 패치 스티칭 전략을 도입하여 물리적 일관성과 시각적 충실도를 높였습니다.\n2) Why is the work important? (연구의 중요성) 이 연구는 고해상도 데이터가 제한적인 환경 과학 분야에서 장기간의 고해상도 예측을 가능하게 하는 강력한 방법론을 제공합니다. G5NR과 같이 학습 기간이 2년으로 제한된 고해상도 데이터셋을 사용하더라도, MERRA-2의 20년치 장기 시계열 정보로부터 학습된 지식을 효과적으로 전이함으로써, 학습 기간을 넘어선 시점(Out-of-Data, OOD)에서도 안정적인 자기회귀적 예측을 수행할 수 있습니다. 이는 환경 노출 평가의 정확도를 높이고 장기적인 환경 모니터링 시스템을 구축하는 데 필수적입니다.\n3) What is the literature gap? (기존 연구의 한계점) 기존 통계적 다운스케일링은 복잡한 비선형 다중 스케일 종속성을 포착하지 못했습니다. 딥러닝 기반의 결정론적 모델(U-Net)은 예측 결과가 지나치게 부드러워지는(oversmoothing) 경향이 있어 미세한 공간적 변동성을 놓쳤습니다. 변이형 오토인코더(VAE)와 같은 생성 모델은 종종 모델 붕괴(model collapse), 분산 과소평가, 그리고 불안정한 학습 문제를 겪었습니다. 또한, 고해상도 데이터가 부족한 경우, 기존 전이 학습 방법론은 ‘부정적 전이(negative transfer)‘나 ‘파국적 망각(catastrophic forgetting)‘의 위험에 노출되었습니다.\n4) How is the gap filled? (해결 방안) 본 연구는 두 가지 핵심 전략으로 한계를 극복합니다. 첫째, 고정된 가중치 전이 인코더를 사용하여 MERRA-2의 장기 시공간 지식을 보존하고, G5NR 학습 시 파국적 망각을 방지합니다. 또한, Wasserstein Distance 분석을 통해 소스(MERRA-2)와 타겟(G5NR) 도메인 간의 유사성이 높음을 정량적으로 검증하여 부정적 전이의 위험을 최소화했습니다. 둘째, DDPM을 메인 다운스케일링 모델로 채택하여, 결정론적 모델의 과도한 부드러움 문제를 해결하고 VAE의 불안정성 없이 고주파 디테일과 현실적인 미세 스케일 구조를 재구성할 수 있게 했습니다.\n5) What is achieved with the new method? (달성한 성과) Table 3 (Validation performance of downscaling models) 분석 결과, Large DDPM 모델은 비교 모델인 Large U-Net 및 Large VAE 대비 가장 안정적이고 우수한 성능을 달성했습니다.\n모델 / 시즌, 지역 Season 1, A0 Season 3, A1 Season 4, A1 Large DDPM R² (Mean) 0.89 0.99 0.90 Large U-Net R² (Mean) 0.94 0.70 0.82 Large VAE R² (Mean) 0.07 0.02 0.10 Large DDPM RMSE (Mean) 0.19 0.06 0.14 Large U-Net RMSE (Mean) 0.02 0.04 0.03 R² 성능: Large DDPM은 모든 시즌과 지역에서 $R^2$ 값이 0.77에서 0.99 사이로 매우 높고 안정적입니다. 특히 Season 3, Area 1에서 $R^2$ **0.99(0.01)**를 달성하여 데이터 변동성의 거의 전부를 설명했습니다. 이는 U-Net의 불안정한 $R^2$ (최저 0.65) 및 VAE의 극도로 낮은 $R^2$ (최저 0.01)와 대조됩니다. RMSE 성능: DDPM의 RMSE는 U-Net보다 수치적으로 높게 나타나지만, 이는 DDPM이 생성 모델로서 데이터의 높은 변동성을 포착하기 때문에 예상되는 결과입니다. DDPM은 높은 $R^2$와 함께 물리적으로 일관된 공간적/시간적 패턴을 보존하여, 단순한 결정론적 예측을 넘어선 고품질 재구성을 입증했습니다. 6) What data are used? (사용 데이터셋) 변수: 먼지 소광 에어로졸 광학 깊이(Dust Extinction AOD) at 550 nm. (단변량(Univariate) 다운스케일링). 저해상도 소스 도메인 ($X$): NASA MERRA-2 재분석 데이터. 해상도 $\\sim 50 \\text{ km} (0.5^\\circ \\times 0.625^\\circ)$. 기간은 2000년 1월 1일 ~ 2024년 12월 31일. 고해상도 타겟 도메인 ($Y$): GEOS-5 Nature Run (G5NR) 시뮬레이션 데이터. 해상도 $\\sim 7 \\text{ km} (0.0625^\\circ)$. 기간은 2005년 6월 ~ 2007년 5월 (오버랩 기간). 지역: Area 0 (아프가니스탄-키르기스스탄) 및 Area 1 (남서아시아/걸프 국가 및 지부티). 추가 입력 변수 ($X_{other}$): 고도(Elevation), 위도/경도, 계절 지수, 데이터셋 시작일로부터의 일수, 정규화된 연도 정보. 7) What are the limitations? (저자가 언급한 한계점) 단변량(Univariate) 설계의 한계: 실제 대기 시스템은 다변량이며, 먼지 AOD 외의 다른 기상 변수(예: 에어로졸 구성, 수직 혼합)를 포함하지 않아 교차 변수 구조를 학습하는 데 제한이 있습니다. 높은 계산 비용: DDPM의 다단계 노이즈 제거 과정(1000 타임스텝)과 고해상도 출력을 위한 밀집 패치 기반 추론으로 인해 계산 비용이 높습니다. 자기회귀적 예측의 제약: OOD 예측이 순차적으로 이루어지기 때문에, 예측 날짜가 멀어질수록 필요한 자기회귀 단계가 증가하여 장기 예측 및 운영 환경에서의 사용이 어렵습니다. 3. 아키텍처 및 방법론 (Architecture \u0026 Methodology) Figure 분석: 메인 아키텍처 (Figure 1) 본 다운스케일링 프레임워크는 두 단계로 구성된 전이 학습 파이프라인을 따릅니다.\nA. Small MERRA-2 Model Pre-training (작은 MERRA-2 모델 사전 학습)\n목표: 장기간의 저해상도 MERRA-2 데이터에서 장거리 시공간 구조를 학습합니다. 모델: 작은 U-Net 모델($f_{U-Net}^{\\psi}$)을 사용합니다. 입력: $T_{lag}$일 동안의 MERRA-2 시계열 데이터($x_{t-T_{lag}+1:t}$). 출력: 다음 날의 MERRA-2 예측값($\\hat{x}_{i,j,t+1}$). B. Transfer to Main Model (메인 모델로 전이)\n과정: 사전 학습된 U-Net 모델($f_{U-Net}^{\\psi}$)의 인코더($\\phi_{\\psi}$) 가중치를 **고정(weight frozen)**합니다. 디코더는 폐기됩니다. 특징 추출: 고정된 인코더($\\phi_{\\psi}$)를 G5NR 시계열($y_{t-T_{lag}+1:t}$)에 적용하여 G5NR 시퀀스에 대한 풍부한 잠재 특징 표현($\\phi_{\\psi}(y_{t-T_{lag}+1:t})$)을 추출합니다. 이 특징은 고해상도 예측을 위한 가이드 역할을 합니다. C. Main Large Downscaling Model (메인 대형 다운스케일링 모델)\n모델: 대형 DDPM($f_{DDPM}^{\\theta}$)을 사용합니다. 입력 (Inputs): 다음 날의 MERRA-2 데이터($x_{i,j,t+1}$). 고도($x_{ele,i,j}$). 기타 지리적/시간적 변수($x_{other,i,j}$). 전이 특징 (Transfer Feature): 고정된 인코더에서 추출된 잠재 특징($\\phi_{\\psi}(y_{t-T_{lag}+1:t})$). 출력: 다음 날의 고해상도 G5NR 먼지 소광 예측 이미지($\\hat{y}_{i,j,t+1}$). 후처리: DDPM의 출력은 패치 스티칭(Patch stitching) 과정을 거쳐 최종 고해상도 이미지로 재구성됩니다. 수식 상세 1. Small Model의 자기회귀적 예측 (Eq. 1): MERRA-2의 시계열 입력 $x_{t-T_{lag}+1:t}$를 사용하여 다음 날의 MERRA-2 값 $\\hat{x}{i,j,t+1}$을 예측합니다. $$ \\hat{x}{i,j,t+1} = f_{\\theta}(x_{t-T_{lag}+1:t}) $$\n2. Main Downscaling Model의 예측 (Eq. 2): 메인 모델 $f_{\\theta}$는 다음 날의 MERRA-2, 고도, 기타 변수, 그리고 고정된 인코더 $\\phi_{\\psi}$를 통해 G5NR 시계열에서 추출된 전이 특징을 통합하여 다음 날의 G5NR 값 $\\hat{y}{i,j,t+1}$을 예측합니다. $$ \\hat{y}{i,j,t+1} = f_{\\theta}(x_{i,j,t+1}, x_{ele,i,j}, x_{other,i,j}, \\phi_{\\psi}(y_{t-T_{lag}+1:t})) $$\n3. Loss Function (Eq. 3): 모델의 손실 함수는 태스크 손실($\\mathcal{L}{data}$)과 $L_2$ 정규화(가중치 감소) 항으로 구성됩니다. 전이된 인코더 $\\phi{\\psi}$의 파라미터는 고정되어 정규화 항에서 제외됩니다. $$ \\mathcal{L}(\\Theta) = \\mathcal{L}{data}(\\Theta) + \\lambda{wd} \\sum_{\\rho \\in \\mathcal{P}{train}} ||\\rho||{2}^{2} $$\nDDPM의 $\\mathcal{L}_{data}$는 squared-cosine noise schedule을 사용합니다. U-Net의 $\\mathcal{L}_{data}$는 픽셀 단위 MAE(Mean Absolute Error) 손실을 사용합니다. VAE의 $\\mathcal{L}_{data}$는 KL Divergence와 스케일된 이미지 재구성 손실을 결합한 하이브리드 손실을 사용합니다. 4. 패치 스티칭 (Patch Stitching) - 최종 예측 (Eq. 9): 추론 시, 겹치는 패치들의 예측값 $\\hat{Y}{i}(y, x)$에 Hann 윈도우 가중치 $W{i}(y, x)$를 적용하여 가중 합 이미지 $S(y, x)$와 가중치 이미지 $Z(y, x)$를 구한 후, 최종 스티칭된 이미지 $\\hat{Y}(y, x)$를 계산합니다. $$ \\hat{Y}(y, x) = \\frac{S(y, x)}{\\max{Z(y, x), \\epsilon}} $$ 여기서 $S(y, x) = \\sum_{i} \\mathbb{1}{(y, x) \\in Q_{i}} W_{i}(y, x) \\hat{Y}{i}(y, x)$ 이고, $Z(y, x) = \\sum{i} \\mathbb{1}{(y, x) \\in Q_{i}} W_{i}(y, x)$ 입니다. ($\\epsilon$은 수치적 안전을 위한 작은 상수).\nVanilla U-Net 비교 특징 Vanilla U-Net (일반적인 다운스케일링) 제안된 모델 (Transfer-DDPM) 기본 구조 인코더-디코더 (결정론적) 인코더-DDPM (생성적) 핵심 모듈 추가/수정 없음 Transfer Encoder ($\\phi_{\\psi}$): MERRA-2 사전 학습 후 가중치 고정 및 특징 전이. 디코더 역할 결정론적 픽셀 값 예측 DDPM: 노이즈 제거를 통한 확률적 고주파 디테일 생성. 입력 특징 저해상도 입력 및 기타 공변량 저해상도 입력 + 고정된 전이 특징 + 고도/지리적/시간적 변수. 출력 후처리 일반적인 이미지 재구성 Halo-and-Hann Patch Stitching: 에지 효과 및 블록 현상 제거. 목표 픽셀 단위 정확도 (MAE/MSE 최소화) 물리적 일관성 및 고주파 디테일 재구성. 4. 태그 제안 (Tags Suggestion) Spatiotemporal Downscaling (시공간 다운스케일링) Transfer Learning (전이 학습) Diffusion Models (확산 모델) Aerosol Optical Depth (AOD) U-Net Architecture (U-Net 아키텍처) ",
  "wordCount" : "1526",
  "inLanguage": "en",
  "datePublished": "2025-12-01T00:00:00Z",
  "dateModified": "2025-12-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hanwo-ol.github.io/Unet_master/posts/spatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Research Agent Knowledge Base",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hanwo-ol.github.io/Unet_master/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hanwo-ol.github.io/Unet_master/" accesskey="h" title="Research Agent Knowledge Base (Alt + H)">Research Agent Knowledge Base</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hanwo-ol.github.io/Unet_master/">Home</a>&nbsp;»&nbsp;<a href="https://hanwo-ol.github.io/Unet_master/posts/">Posts</a></div>
    <h1 class="post-title">
      Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models
    </h1>
    <div class="post-meta">&lt;span title=&#39;2025-12-01 00:00:00 &#43;0000 UTC&#39;&gt;December 1, 2025&lt;/span&gt;&amp;nbsp;·&amp;nbsp;8 min

</div>
  </header> 
  <div class="post-content"><h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>We present a transfer-learning generative downscaling framework to reconstruct fine resolution satellite images from coarse scale inputs. Our approach combines a lightweight U-Net transfer encoder with a diffusion-based generative model. The simpler U-Net is first pretrained on a long time series of coarse resolution data to learn spatiotemporal representations; its encoder is then frozen and transferred to a larger downscaling model as physically meaningful latent features. Our application uses NASA&rsquo;s MERRA-2 reanalysis as the low resolution source domain (50 km) and the GEOS-5 Nature Run (G5NR) as the high resolution target (7 km). Our study area included a large area in Asia, which was made computationally tractable by splitting into two subregions and four seasons. We conducted domain similarity analysis using Wasserstein distances confirmed minimal distributional shift between MERRA-2 and G5NR, validating the safety of parameter frozen transfer. Across seasonal regional splits, our model achieved excellent performance (R2 = 0.65 to 0.94), outperforming comparison models including deterministic U-Nets, variational autoencoders, and prior transfer learning baselines. Out of data evaluations using semivariograms, ACF/PACF, and lag-based RMSE/R2 demonstrated that the predicted downscaled images preserved physically consistent spatial variability and temporal autocorrelation, enabling stable autoregressive reconstruction beyond the G5NR record. These results show that transfer enhanced diffusion models provide a robust and physically coherent solution for downscaling a long time series of coarse resolution images with limited training periods. This advancement has significant implications for improving environmental exposure assessment and long term environmental monitoring.</p>
<h2 id="pdf-download">PDF Download<a hidden class="anchor" aria-hidden="true" href="#pdf-download">#</a></h2>
<h2 id="pdf-download-1">PDF Download<a hidden class="anchor" aria-hidden="true" href="#pdf-download-1">#</a></h2>
<p><a href="//172.22.138.185/Research_pdf/2512.05139v1.pdf">Local PDF View</a> | <a href="http://arxiv.org/abs/2512.05139v1">Arxiv Original</a></p>
<h2 id="research-agent---draft-refiner-module-상세-리포트">Research Agent - Draft Refiner Module 상세 리포트<a hidden class="anchor" aria-hidden="true" href="#research-agent---draft-refiner-module-상세-리포트">#</a></h2>
<hr>
<h3 id="1-요약-executive-summary">1. 요약 (Executive Summary)<a hidden class="anchor" aria-hidden="true" href="#1-요약-executive-summary">#</a></h3>
<p>본 논문은 조악한 해상도의 위성 이미지로부터 미세 해상도의 이미지를 재구성하기 위한 <strong>전이 학습 기반의 생성적 다운스케일링 프레임워크</strong>를 제안합니다. 이 프레임워크는 장기간의 환경 모니터링 및 노출 평가 개선에 중요한 기여를 합니다.</p>
<ul>
<li><strong>프레임워크 구성:</strong> 경량 시간적 U-Net 전이 인코더와 확산 기반 생성 모델(Denoising Diffusion Probabilistic Model, DDPM)을 결합하여 20년 기간 동안 일별 미세 해상도 다운스케일링 이미지를 생성합니다.</li>
<li><strong>전이 학습 전략:</strong> 단순한 U-Net을 장기간의 저해상도 데이터(MERRA-2)로 사전 학습하여 시공간적 표현을 학습합니다. 이후 이 U-Net의 인코더 가중치를 고정(frozen)하고, 이를 물리적으로 의미 있는 잠재 특징으로 추출하여 더 큰 다운스케일링 모델(DDPM)에 전이합니다.</li>
<li><strong>데이터셋:</strong> 저해상도 소스 도메인으로 NASA의 MERRA-2 재분석 데이터(~50 km 해상도)를, 고해상도 타겟 도메인으로 GEOS-5 Nature Run (G5NR) 데이터(~7 km 해상도)의 먼지 소광 AOD(Aerosol Optical Depth)를 사용합니다.</li>
<li><strong>성능 및 안정성:</strong> 결정론적 U-Net, 변이형 오토인코더(VAE) 등 비교 모델 대비 우수한 성능(R2 0.65~0.94)을 달성했습니다. Wasserstein Distance 분석을 통해 MERRA-2와 G5NR 간의 최소한의 분포적 차이(minimal distributional shift)를 확인하여 전이 학습의 안전성을 검증했습니다.</li>
<li><strong>물리적 일관성:</strong> Semivariogram, ACF/PACF 분석을 통해 예측된 다운스케일링 이미지가 물리적으로 일관된 공간적 변동성과 시간적 자기상관성을 보존하며, G5NR 기록 기간을 넘어선 안정적인 자기회귀적 재구성을 가능하게 함을 입증했습니다.</li>
</ul>
<hr>
<h3 id="2-7가지-핵심-질문-분석-key-analysis">2. 7가지 핵심 질문 분석 (Key Analysis)<a hidden class="anchor" aria-hidden="true" href="#2-7가지-핵심-질문-분석-key-analysis">#</a></h3>
<h4 id="1-what-is-new-in-the-work-기존-연구와의-차별점">1) What is new in the work? (기존 연구와의 차별점)<a hidden class="anchor" aria-hidden="true" href="#1-what-is-new-in-the-work-기존-연구와의-차별점">#</a></h4>
<p>본 연구는 <strong>전이 학습 인코더와 자기회귀적 생성 모델(DDPM)을 결합한 2단계 다운스케일링 프레임워크</strong>를 제안한 것이 가장 큰 차별점입니다. 기존 연구들이 결정론적 U-Net이나 불안정한 GAN/VAE를 사용했던 것과 달리, 본 모델은 장기간의 저해상도 데이터(MERRA-2)에서 학습된 강력한 시공간적 표현을 고정된 인코더를 통해 추출하여, 고해상도 생성 모델(DDPM)에 입력으로 제공합니다. 또한, 이미지 재구성 시 블록 현상 및 에지 효과를 제거하기 위해 <strong>Halo-and-Hann 패치 스티칭</strong> 전략을 도입하여 물리적 일관성과 시각적 충실도를 높였습니다.</p>
<h4 id="2-why-is-the-work-important-연구의-중요성">2) Why is the work important? (연구의 중요성)<a hidden class="anchor" aria-hidden="true" href="#2-why-is-the-work-important-연구의-중요성">#</a></h4>
<p>이 연구는 고해상도 데이터가 제한적인 환경 과학 분야에서 장기간의 고해상도 예측을 가능하게 하는 강력한 방법론을 제공합니다. G5NR과 같이 학습 기간이 2년으로 제한된 고해상도 데이터셋을 사용하더라도, MERRA-2의 20년치 장기 시계열 정보로부터 학습된 지식을 효과적으로 전이함으로써, 학습 기간을 넘어선 시점(Out-of-Data, OOD)에서도 안정적인 자기회귀적 예측을 수행할 수 있습니다. 이는 환경 노출 평가의 정확도를 높이고 장기적인 환경 모니터링 시스템을 구축하는 데 필수적입니다.</p>
<h4 id="3-what-is-the-literature-gap-기존-연구의-한계점">3) What is the literature gap? (기존 연구의 한계점)<a hidden class="anchor" aria-hidden="true" href="#3-what-is-the-literature-gap-기존-연구의-한계점">#</a></h4>
<p>기존 통계적 다운스케일링은 복잡한 비선형 다중 스케일 종속성을 포착하지 못했습니다. 딥러닝 기반의 결정론적 모델(U-Net)은 예측 결과가 지나치게 부드러워지는(oversmoothing) 경향이 있어 미세한 공간적 변동성을 놓쳤습니다. 변이형 오토인코더(VAE)와 같은 생성 모델은 종종 모델 붕괴(model collapse), 분산 과소평가, 그리고 불안정한 학습 문제를 겪었습니다. 또한, 고해상도 데이터가 부족한 경우, 기존 전이 학습 방법론은 &lsquo;부정적 전이(negative transfer)&lsquo;나 &lsquo;파국적 망각(catastrophic forgetting)&lsquo;의 위험에 노출되었습니다.</p>
<h4 id="4-how-is-the-gap-filled-해결-방안">4) How is the gap filled? (해결 방안)<a hidden class="anchor" aria-hidden="true" href="#4-how-is-the-gap-filled-해결-방안">#</a></h4>
<p>본 연구는 두 가지 핵심 전략으로 한계를 극복합니다. 첫째, <strong>고정된 가중치 전이 인코더</strong>를 사용하여 MERRA-2의 장기 시공간 지식을 보존하고, G5NR 학습 시 파국적 망각을 방지합니다. 또한, Wasserstein Distance 분석을 통해 소스(MERRA-2)와 타겟(G5NR) 도메인 간의 유사성이 높음을 정량적으로 검증하여 부정적 전이의 위험을 최소화했습니다. 둘째, <strong>DDPM</strong>을 메인 다운스케일링 모델로 채택하여, 결정론적 모델의 과도한 부드러움 문제를 해결하고 VAE의 불안정성 없이 고주파 디테일과 현실적인 미세 스케일 구조를 재구성할 수 있게 했습니다.</p>
<h4 id="5-what-is-achieved-with-the-new-method-달성한-성과">5) What is achieved with the new method? (달성한 성과)<a hidden class="anchor" aria-hidden="true" href="#5-what-is-achieved-with-the-new-method-달성한-성과">#</a></h4>
<p><strong>Table 3 (Validation performance of downscaling models)</strong> 분석 결과, Large DDPM 모델은 비교 모델인 Large U-Net 및 Large VAE 대비 가장 안정적이고 우수한 성능을 달성했습니다.</p>
<table>
<thead>
<tr>
<th style="text-align:left">모델 / 시즌, 지역</th>
<th style="text-align:center">Season 1, A0</th>
<th style="text-align:center">Season 3, A1</th>
<th style="text-align:center">Season 4, A1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Large DDPM R² (Mean)</strong></td>
<td style="text-align:center">0.89</td>
<td style="text-align:center"><strong>0.99</strong></td>
<td style="text-align:center">0.90</td>
</tr>
<tr>
<td style="text-align:left">Large U-Net R² (Mean)</td>
<td style="text-align:center">0.94</td>
<td style="text-align:center">0.70</td>
<td style="text-align:center">0.82</td>
</tr>
<tr>
<td style="text-align:left">Large VAE R² (Mean)</td>
<td style="text-align:center">0.07</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0.10</td>
</tr>
<tr>
<td style="text-align:left"><strong>Large DDPM RMSE (Mean)</strong></td>
<td style="text-align:center">0.19</td>
<td style="text-align:center"><strong>0.06</strong></td>
<td style="text-align:center">0.14</td>
</tr>
<tr>
<td style="text-align:left">Large U-Net RMSE (Mean)</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0.04</td>
<td style="text-align:center">0.03</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>R² 성능:</strong> Large DDPM은 모든 시즌과 지역에서 $R^2$ 값이 0.77에서 0.99 사이로 매우 높고 안정적입니다. 특히 Season 3, Area 1에서 $R^2$ **0.99(0.01)**를 달성하여 데이터 변동성의 거의 전부를 설명했습니다. 이는 U-Net의 불안정한 $R^2$ (최저 0.65) 및 VAE의 극도로 낮은 $R^2$ (최저 0.01)와 대조됩니다.</li>
<li><strong>RMSE 성능:</strong> DDPM의 RMSE는 U-Net보다 수치적으로 높게 나타나지만, 이는 DDPM이 생성 모델로서 데이터의 높은 변동성을 포착하기 때문에 예상되는 결과입니다. DDPM은 높은 $R^2$와 함께 물리적으로 일관된 공간적/시간적 패턴을 보존하여, 단순한 결정론적 예측을 넘어선 고품질 재구성을 입증했습니다.</li>
</ul>
<h4 id="6-what-data-are-used-사용-데이터셋">6) What data are used? (사용 데이터셋)<a hidden class="anchor" aria-hidden="true" href="#6-what-data-are-used-사용-데이터셋">#</a></h4>
<ul>
<li><strong>변수:</strong> 먼지 소광 에어로졸 광학 깊이(Dust Extinction AOD) at 550 nm. (단변량(Univariate) 다운스케일링).</li>
<li><strong>저해상도 소스 도메인 ($X$):</strong> NASA MERRA-2 재분석 데이터. 해상도 $\sim 50 \text{ km} (0.5^\circ \times 0.625^\circ)$. 기간은 2000년 1월 1일 ~ 2024년 12월 31일.</li>
<li><strong>고해상도 타겟 도메인 ($Y$):</strong> GEOS-5 Nature Run (G5NR) 시뮬레이션 데이터. 해상도 $\sim 7 \text{ km} (0.0625^\circ)$. 기간은 2005년 6월 ~ 2007년 5월 (오버랩 기간).</li>
<li><strong>지역:</strong> Area 0 (아프가니스탄-키르기스스탄) 및 Area 1 (남서아시아/걸프 국가 및 지부티).</li>
<li><strong>추가 입력 변수 ($X_{other}$):</strong> 고도(Elevation), 위도/경도, 계절 지수, 데이터셋 시작일로부터의 일수, 정규화된 연도 정보.</li>
</ul>
<h4 id="7-what-are-the-limitations-저자가-언급한-한계점">7) What are the limitations? (저자가 언급한 한계점)<a hidden class="anchor" aria-hidden="true" href="#7-what-are-the-limitations-저자가-언급한-한계점">#</a></h4>
<ol>
<li><strong>단변량(Univariate) 설계의 한계:</strong> 실제 대기 시스템은 다변량이며, 먼지 AOD 외의 다른 기상 변수(예: 에어로졸 구성, 수직 혼합)를 포함하지 않아 교차 변수 구조를 학습하는 데 제한이 있습니다.</li>
<li><strong>높은 계산 비용:</strong> DDPM의 다단계 노이즈 제거 과정(1000 타임스텝)과 고해상도 출력을 위한 밀집 패치 기반 추론으로 인해 계산 비용이 높습니다.</li>
<li><strong>자기회귀적 예측의 제약:</strong> OOD 예측이 순차적으로 이루어지기 때문에, 예측 날짜가 멀어질수록 필요한 자기회귀 단계가 증가하여 장기 예측 및 운영 환경에서의 사용이 어렵습니다.</li>
</ol>
<hr>
<h3 id="3-아키텍처-및-방법론-architecture--methodology">3. 아키텍처 및 방법론 (Architecture &amp; Methodology)<a hidden class="anchor" aria-hidden="true" href="#3-아키텍처-및-방법론-architecture--methodology">#</a></h3>
<h4 id="figure-분석-메인-아키텍처-figure-1">Figure 분석: 메인 아키텍처 (Figure 1)<a hidden class="anchor" aria-hidden="true" href="#figure-분석-메인-아키텍처-figure-1">#</a></h4>
<p>본 다운스케일링 프레임워크는 두 단계로 구성된 전이 학습 파이프라인을 따릅니다.</p>
<p><strong>A. Small MERRA-2 Model Pre-training (작은 MERRA-2 모델 사전 학습)</strong></p>
<ul>
<li><strong>목표:</strong> 장기간의 저해상도 MERRA-2 데이터에서 장거리 시공간 구조를 학습합니다.</li>
<li><strong>모델:</strong> 작은 U-Net 모델($f_{U-Net}^{\psi}$)을 사용합니다.</li>
<li><strong>입력:</strong> $T_{lag}$일 동안의 MERRA-2 시계열 데이터($x_{t-T_{lag}+1:t}$).</li>
<li><strong>출력:</strong> 다음 날의 MERRA-2 예측값($\hat{x}_{i,j,t+1}$).</li>
</ul>
<p><strong>B. Transfer to Main Model (메인 모델로 전이)</strong></p>
<ul>
<li><strong>과정:</strong> 사전 학습된 U-Net 모델($f_{U-Net}^{\psi}$)의 인코더($\phi_{\psi}$) 가중치를 **고정(weight frozen)**합니다. 디코더는 폐기됩니다.</li>
<li><strong>특징 추출:</strong> 고정된 인코더($\phi_{\psi}$)를 G5NR 시계열($y_{t-T_{lag}+1:t}$)에 적용하여 G5NR 시퀀스에 대한 풍부한 잠재 특징 표현($\phi_{\psi}(y_{t-T_{lag}+1:t})$)을 추출합니다. 이 특징은 고해상도 예측을 위한 가이드 역할을 합니다.</li>
</ul>
<p><strong>C. Main Large Downscaling Model (메인 대형 다운스케일링 모델)</strong></p>
<ul>
<li><strong>모델:</strong> 대형 DDPM($f_{DDPM}^{\theta}$)을 사용합니다.</li>
<li><strong>입력 (Inputs):</strong>
<ol>
<li>다음 날의 MERRA-2 데이터($x_{i,j,t+1}$).</li>
<li>고도($x_{ele,i,j}$).</li>
<li>기타 지리적/시간적 변수($x_{other,i,j}$).</li>
<li><strong>전이 특징 (Transfer Feature):</strong> 고정된 인코더에서 추출된 잠재 특징($\phi_{\psi}(y_{t-T_{lag}+1:t})$).</li>
</ol>
</li>
<li><strong>출력:</strong> 다음 날의 고해상도 G5NR 먼지 소광 예측 이미지($\hat{y}_{i,j,t+1}$).</li>
<li><strong>후처리:</strong> DDPM의 출력은 <strong>패치 스티칭(Patch stitching)</strong> 과정을 거쳐 최종 고해상도 이미지로 재구성됩니다.</li>
</ul>
<h4 id="수식-상세">수식 상세<a hidden class="anchor" aria-hidden="true" href="#수식-상세">#</a></h4>
<p><strong>1. Small Model의 자기회귀적 예측 (Eq. 1):</strong>
MERRA-2의 시계열 입력 $x_{t-T_{lag}+1:t}$를 사용하여 다음 날의 MERRA-2 값 $\hat{x}<em>{i,j,t+1}$을 예측합니다.
$$ \hat{x}</em>{i,j,t+1} = f_{\theta}(x_{t-T_{lag}+1:t}) $$</p>
<p><strong>2. Main Downscaling Model의 예측 (Eq. 2):</strong>
메인 모델 $f_{\theta}$는 다음 날의 MERRA-2, 고도, 기타 변수, 그리고 고정된 인코더 $\phi_{\psi}$를 통해 G5NR 시계열에서 추출된 전이 특징을 통합하여 다음 날의 G5NR 값 $\hat{y}<em>{i,j,t+1}$을 예측합니다.
$$ \hat{y}</em>{i,j,t+1} = f_{\theta}(x_{i,j,t+1}, x_{ele,i,j}, x_{other,i,j}, \phi_{\psi}(y_{t-T_{lag}+1:t})) $$</p>
<p><strong>3. Loss Function (Eq. 3):</strong>
모델의 손실 함수는 태스크 손실($\mathcal{L}<em>{data}$)과 $L_2$ 정규화(가중치 감소) 항으로 구성됩니다. 전이된 인코더 $\phi</em>{\psi}$의 파라미터는 고정되어 정규화 항에서 제외됩니다.
$$ \mathcal{L}(\Theta) = \mathcal{L}<em>{data}(\Theta) + \lambda</em>{wd} \sum_{\rho \in \mathcal{P}<em>{train}} ||\rho||</em>{2}^{2} $$</p>
<ul>
<li>DDPM의 $\mathcal{L}_{data}$는 squared-cosine noise schedule을 사용합니다.</li>
<li>U-Net의 $\mathcal{L}_{data}$는 픽셀 단위 MAE(Mean Absolute Error) 손실을 사용합니다.</li>
<li>VAE의 $\mathcal{L}_{data}$는 KL Divergence와 스케일된 이미지 재구성 손실을 결합한 하이브리드 손실을 사용합니다.</li>
</ul>
<p><strong>4. 패치 스티칭 (Patch Stitching) - 최종 예측 (Eq. 9):</strong>
추론 시, 겹치는 패치들의 예측값 $\hat{Y}<em>{i}(y, x)$에 Hann 윈도우 가중치 $W</em>{i}(y, x)$를 적용하여 가중 합 이미지 $S(y, x)$와 가중치 이미지 $Z(y, x)$를 구한 후, 최종 스티칭된 이미지 $\hat{Y}(y, x)$를 계산합니다.
$$ \hat{Y}(y, x) = \frac{S(y, x)}{\max{Z(y, x), \epsilon}} $$
여기서 $S(y, x) = \sum_{i} \mathbb{1}{(y, x) \in Q_{i}} W_{i}(y, x) \hat{Y}<em>{i}(y, x)$ 이고, $Z(y, x) = \sum</em>{i} \mathbb{1}{(y, x) \in Q_{i}} W_{i}(y, x)$ 입니다. ($\epsilon$은 수치적 안전을 위한 작은 상수).</p>
<h4 id="vanilla-u-net-비교">Vanilla U-Net 비교<a hidden class="anchor" aria-hidden="true" href="#vanilla-u-net-비교">#</a></h4>
<table>
<thead>
<tr>
<th style="text-align:left">특징</th>
<th style="text-align:left">Vanilla U-Net (일반적인 다운스케일링)</th>
<th style="text-align:left">제안된 모델 (Transfer-DDPM)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>기본 구조</strong></td>
<td style="text-align:left">인코더-디코더 (결정론적)</td>
<td style="text-align:left">인코더-DDPM (생성적)</td>
</tr>
<tr>
<td style="text-align:left"><strong>핵심 모듈 추가/수정</strong></td>
<td style="text-align:left">없음</td>
<td style="text-align:left"><strong>Transfer Encoder ($\phi_{\psi}$)</strong>: MERRA-2 사전 학습 후 가중치 고정 및 특징 전이.</td>
</tr>
<tr>
<td style="text-align:left"><strong>디코더 역할</strong></td>
<td style="text-align:left">결정론적 픽셀 값 예측</td>
<td style="text-align:left"><strong>DDPM</strong>: 노이즈 제거를 통한 확률적 고주파 디테일 생성.</td>
</tr>
<tr>
<td style="text-align:left"><strong>입력 특징</strong></td>
<td style="text-align:left">저해상도 입력 및 기타 공변량</td>
<td style="text-align:left">저해상도 입력 + <strong>고정된 전이 특징</strong> + 고도/지리적/시간적 변수.</td>
</tr>
<tr>
<td style="text-align:left"><strong>출력 후처리</strong></td>
<td style="text-align:left">일반적인 이미지 재구성</td>
<td style="text-align:left"><strong>Halo-and-Hann Patch Stitching</strong>: 에지 효과 및 블록 현상 제거.</td>
</tr>
<tr>
<td style="text-align:left"><strong>목표</strong></td>
<td style="text-align:left">픽셀 단위 정확도 (MAE/MSE 최소화)</td>
<td style="text-align:left">물리적 일관성 및 고주파 디테일 재구성.</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="4-태그-제안-tags-suggestion">4. 태그 제안 (Tags Suggestion)<a hidden class="anchor" aria-hidden="true" href="#4-태그-제안-tags-suggestion">#</a></h3>
<ol>
<li>Spatiotemporal Downscaling (시공간 다운스케일링)</li>
<li>Transfer Learning (전이 학습)</li>
<li>Diffusion Models (확산 모델)</li>
<li>Aerosol Optical Depth (AOD)</li>
<li>U-Net Architecture (U-Net 아키텍처)</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/auto-generated/">Auto-Generated</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/draft/">Draft</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hanwo-ol.github.io/Unet_master/posts/multifractal-recalibration-of-neural-networks-for-medical-imaging-segmentation/">
    <span class="title">« Prev</span>
    <br>
    <span>Multifractal Recalibration of Neural Networks for Medical Imaging Segmentation</span>
  </a>
  <a class="next" href="https://hanwo-ol.github.io/Unet_master/posts/satellite-to-street-disaster-impact-estimator/">
    <span class="title">Next »</span>
    <br>
    <span>Satellite to Street : Disaster Impact Estimator</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on twitter"
        href="https://twitter.com/intent/tweet/?text=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f&amp;hashtags=Auto-Generated%2cDraft">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f&amp;title=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models&amp;summary=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models&amp;source=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f&title=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on whatsapp"
        href="https://api.whatsapp.com/send?text=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models%20-%20https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Spatiotemporal Satellite Image Downscaling with Transfer Encoders and Autoregressive Generative Models on telegram"
        href="https://telegram.me/share/url?text=Spatiotemporal%20Satellite%20Image%20Downscaling%20with%20Transfer%20Encoders%20and%20Autoregressive%20Generative%20Models&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2fspatiotemporal-satellite-image-downscaling-with-transfer-encoders-and-autoregressive-generative-models%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://hanwo-ol.github.io/Unet_master/">Research Agent Knowledge Base</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
