<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation | Research Agent Knowledge Base</title>
<meta name="keywords" content="Image Segmentation, Variational Model, UNet Hybrid Architecture, Cahn-Hilliard Equation, Mean Curvature, U-Net">
<meta name="description" content="Abstract To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks.">
<meta name="author" content="">
<link rel="canonical" href="https://hanwo-ol.github.io/Unet_master/posts/robust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation/">
<link crossorigin="anonymous" href="/Unet_master/assets/css/stylesheet.62aa25427797f8efd87301a5b69795dc50df2dbe79a5fba0648cc7bb8dbcd7c9.css" integrity="sha256-YqolQneX&#43;O/YcwGltpeV3FDfLb55pfugZIzHu42818k=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/Unet_master/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js" integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://hanwo-ol.github.io/Unet_master/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://hanwo-ol.github.io/Unet_master/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://hanwo-ol.github.io/Unet_master/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://hanwo-ol.github.io/Unet_master/apple-touch-icon.png">
<link rel="mask-icon" href="https://hanwo-ol.github.io/Unet_master/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"
    integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"
    integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
    crossorigin="anonymous"></script>
<style>
    .katex-mathml {
        display: none;
    }
</style>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ]
        });
    });
</script>
<meta property="og:title" content="Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation" />
<meta property="og:description" content="Abstract To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hanwo-ol.github.io/Unet_master/posts/robust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-12-08T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-12-08T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation"/>
<meta name="twitter:description" content="Abstract To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation",
      "item": "https://hanwo-ol.github.io/Unet_master/posts/robust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation",
  "name": "Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation",
  "description": "Abstract To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks.",
  "keywords": [
    "Image Segmentation", "Variational Model", "UNet Hybrid Architecture", "Cahn-Hilliard Equation", "Mean Curvature", "U-Net"
  ],
  "articleBody": "Abstract To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.\nPDF Download Local PDF View | Arxiv Original\n이 논문은 **“ROBUST VARIATIONAL MODEL BASED TAILORED UNET: LEVERAGING EDGE DETECTOR AND MEAN CURVATURE FOR IMPROVED IMAGE SEGMENTATION”**에 대한 상세 분석 리포트입니다.\n1. 요약 (Executive Summary) 본 논문은 경계가 흐릿하거나 파편화된 노이즈 이미지의 분할 문제를 해결하기 위해 **VM_TUNet (Variational Model Based Tailored UNet)**이라는 강건한 하이브리드 프레임워크를 제안합니다.\n하이브리드 접근 방식: 변분법적 부분 미분 방정식(PDEs)의 해석 가능성 및 경계 평활화 이점을 딥러닝의 강력한 특징 표현 능력과 통합합니다. 수정된 Cahn-Hilliard 방정식: 물리적 사전 지식(Physical Priors), 엣지 검출기($g(|\\nabla f|)$), 그리고 평균 곡률 항($\\nabla \\cdot (\\nabla u / |\\nabla u|)$)을 통합하여 노이즈 환경에서 경계의 정확도와 안정성을 높입니다. 협력적 모듈 아키텍처: F 모듈 (Frequency Domain Preprocessing): 효율적인 주파수 영역 전처리를 수행하여 국소 최솟값(local minima)을 피하고 후속 최적화를 위한 더 나은 초기 상태를 제공합니다. T 모듈 (Tailored Finite Point Method): 정확하고 안정적인 국소 계산을 보장하며, 알고리즘의 신뢰성을 뒷받침하는 조건부 수치 안정성 정리(Stability Estimate)를 제공합니다. 성과: 3가지 벤치마크 데이터셋(ECSSD, HKU-IS, DUT-OMRON)에서 광범위한 실험을 통해 순수 CNN 기반 모델 대비 경쟁적인 정량적 결과와 향상된 시각적 품질을 달성했습니다. 효율성: 트랜스포머 기반 모델(Swin-UNet)과 유사한 성능을 달성하면서도 합리적인 계산 비용을 유지하여 성능과 효율성 간의 균형을 맞춥니다. 2. 7가지 핵심 질문 분석 (Key Analysis) 1) What is new in the work? (기존 연구와의 차별점) 본 연구는 변분법적 PDE와 딥러닝을 결합한 하이브리드 프레임워크인 VM_TUNet을 제안합니다. 가장 큰 차별점은 수정된 Cahn-Hilliard 방정식에 엣지 검출기($g(|\\nabla f|)$)와 평균 곡률 항($\\nabla \\cdot (\\nabla u / |\\nabla u|)$)과 같은 물리적 사전 지식을 명시적으로 통합했다는 점입니다. 또한, 아키텍처를 효율적인 주파수 영역 전처리(F 모듈)와 안정적인 국소 계산(T 모듈)을 담당하는 두 가지 협력 모듈로 분리하여, 기존의 변분 모델이 겪던 계산 비용 문제와 딥러닝 모델이 노이즈 환경에서 겪는 경계 품질 저하 문제를 동시에 해결하고자 했습니다.\n2) Why is the work important? (연구의 중요성) 이 연구는 노이즈가 심하거나 경계가 모호한 이미지 분할이라는 실질적인 난제를 해결하는 데 중요합니다. 기존의 딥러닝 모델은 강력한 표현 능력을 가졌지만, 노이즈가 많거나 학습 데이터가 제한적일 때 경계의 정확도와 해석 가능성이 떨어지는 한계가 있었습니다. VM_TUNet은 변분법의 **해석 가능성(Interpretability)**과 경계 평활화(Boundary Smoothness) 이점을 딥러닝에 통합함으로써, 노이즈에 강건하며 기하학적으로 일관된 분할 결과를 제공합니다. 특히 T 모듈에 대한 조건부 수치 안정성 정리를 제공하여 알고리즘의 신뢰성을 이론적으로 뒷받침합니다.\n3) What is the literature gap? (기존 연구의 한계점) 기존의 순수 변분 모델은 높은 계산 비용 때문에 대규모 또는 노이즈가 많은 이미지에 실시간으로 적용하기 어려웠으며, 초기화에 민감하고 국소 최솟값에 빠지기 쉬웠습니다. 반면, UNet이나 Swin-UNet 같은 딥러닝 모델은 노이즈가 심한 이미지에서 때때로 파편화되거나 톱니 모양의 경계를 생성하는 등 비정상적인 결과를 초래했습니다. 특히, 기존 하이브리드 모델들조차 저차 PDE에 해당하는 에너지 함수를 사용하기 때문에 미묘한 경계를 보존하는 데 어려움을 겪었습니다.\n4) How is the gap filled? (해결 방안) 본 논문은 F 모듈과 T 모듈을 통해 이 간극을 메웁니다. F 모듈은 **Fourier Spectral Method (FSM)**를 기반으로 주파수 영역에서 효율적인 전처리를 수행하여 노이즈를 줄이고 최적화 초기 상태를 개선합니다. T 모듈은 **Tailored Finite Point Method (TFPM)**를 구현하여 수정된 Cahn-Hilliard 방정식을 반복적으로 풀며 정확하고 안정적인 국소 계산을 수행합니다. 이 변분법적 최적화 과정은 딥러닝 네트워크 내에 통합되어, 네트워크가 데이터 충실도 항 $H(f)$를 학습하도록 함으로써 수동적인 매개변수 튜닝 없이도 노이즈에 강건한 경계 평활화 효과를 얻습니다.\n5) What is achieved with the new method? (달성한 성과) VM_TUNet은 노이즈 환경($\\sigma=0.5$)에서 기존 CNN 및 하이브리드 모델 대비 우수한 성능을 달성했습니다 (Table 2 참조).\n모델 ECSSD Dice (↑) HKU-IS HD95 (↓) DUT-OMRON Dice (↑) UNet $0.873 \\pm 0.004$ $1.602 \\pm 0.012$ $0.868 \\pm 0.003$ Swin-UNet $0.910 \\pm 0.002$ $1.001 \\pm 0.007$ $0.905 \\pm 0.001$ DN $0.896 \\pm 0.002$ $1.287 \\pm 0.010$ $0.885 \\pm 0.001$ Ours $0.919 \\pm 0.003$ $0.989 \\pm 0.004$ $0.902 \\pm 0.001$ 정량적 성과: ECSSD 및 HKU-IS에서 가장 높은 Dice 점수와 가장 낮은 HD95(경계 정확도)를 기록하여, 노이즈 조건 하에서 향상된 영역 일치도와 경계 안정성을 입증했습니다. 특히 ECSSD Dice 점수는 Swin-UNet($0.910$)보다 높은 **$0.919$**를 달성했습니다. 효율성 (Table 3): 에포크당 실행 시간은 UNet(5.54s)이나 UNet++(7.36s)보다 길지만, 트랜스포머 기반 Swin-UNet(10.87s) 및 하이브리드 DN(11.05s)과 비교했을 때 합리적인 수준인 23.46s를 기록했습니다. 이는 도입된 모듈이 성능 향상에 기여하면서도 계산 효율성을 크게 저해하지 않음을 시사합니다. 6) What data are used? (사용 데이터셋) 세 가지 벤치마크 데이터셋이 사용되었으며, 모든 이미지에는 다양한 표준 편차($\\sigma$)를 가진 영평균 가우시안 노이즈(zero-mean Gaussian noise)가 인위적으로 추가되었습니다.\nECSSD: 1000개의 의미론적으로 주석이 달린 이미지로, 복잡한 배경과 픽셀 단위 수동 주석이 특징입니다. (시각적 현저성(Saliency) 도메인) HKU-IS: 4447개의 도전적인 이미지로, 낮은 대비 또는 다중 현저 객체를 포함합니다. (시각적 현저성 도메인) DUT-OMRON: 5168개의 고품질 자연 이미지로, 다양하고 복잡한 배경에 하나 이상의 현저 객체를 포함합니다. 7) What are the limitations? (저자가 언급한 한계점) 저자는 다음과 같은 한계점을 언급했습니다.\n성능 개선의 정도: 엣지 선명도, 디테일 유지 및 전반적인 분할 정확도 측면에서 기존 CNN 기반 접근 방식 대비 완만한(modest) 개선을 달성했으며, 트랜스포머 기반 기술과 비교했을 때는 비슷한 수준입니다. 계산 비용: 순수 CNN 모델(UNet, UNet++)에 비해 계산 요구 사항이 높습니다. 이론적 이해 및 확장: 향후 연구에서는 인스턴스 분할(instance segmentation) 및 3D 의료 영상 처리와 같은 더 도전적인 작업으로 모델을 확장하고, 모델의 광범위한 속성에 대한 보다 체계적인 이론적 이해를 개발해야 합니다. 3. 아키텍처 및 방법론 (Architecture \u0026 Methodology) Figure 분석: Robust VM_TUNet 아키텍처 (Figure 1) VM_TUNet은 기존 U-Net의 인코더-디코더 구조를 변분법적 최적화 단계와 딥러닝 특징 학습을 결합한 두 가지 핵심 모듈(F 모듈, T 모듈)로 대체한 하이브리드 구조입니다.\n전체 흐름 (a): 입력 이미지 $f$가 F 모듈을 통과합니다. F 모듈의 출력은 Sigmoid 함수를 거쳐 T 모듈의 입력으로 사용됩니다. T 모듈은 F 모듈의 출력과 $H(f)$ (학습된 데이터 충실도 항)를 입력으로 받아 변분법적 최적화를 수행합니다. T 모듈의 출력 $u_T$는 최종적으로 $W * u_T + b$ (컨볼루션 레이어와 바이어스)를 거쳐 Sigmoid 함수를 통해 최종 분할 출력(output)을 생성합니다. F 모듈 (b): FSM (Fourier Spectral Method) 블록($B_F$)의 시퀀스로 구성되어 있으며, 주파수 영역에서 효율적인 전처리를 담당합니다. T 모듈 (c): TFPM (Tailored Finite Point Method) 블록($B_T$)의 시퀀스로 구현되며, 수정된 Cahn-Hilliard 방정식의 반복적인 수치 해를 계산하여 정확하고 안정적인 국소 계산을 수행합니다. 수식 상세 1. 수정된 Cahn-Hilliard 방정식 (Modified Cahn-Hilliard Equation) 본 논문에서 제안하는 노이즈 이미지 분할을 위한 수정된 Cahn-Hilliard 방정식은 다음과 같습니다 (Eq. 1):\n$$\\frac{\\partial u}{\\partial t} = -\\Delta\\left[\\epsilon \\cdot (\\nabla u) - \\frac{2}{\\epsilon} W’(u)\\right] - \\lambda\\left[u(f-c_1)^2 - (1-u)(f-c_2)^2\\right] + \\mu\\nabla \\cdot \\left(\\frac{\\nabla u}{|\\nabla u|}\\right)$$\n이는 다음의 형태로 변환될 수 있습니다 (Eq. 2):\n$$\\frac{\\partial u}{\\partial t} = -\\Delta\\left(\\epsilon\\Delta u - \\frac{2}{\\epsilon} W’(u)\\right) - \\lambda\\left[u(f-c_1)^2 - (1-u)(f-c_2)^2\\right] + \\mu\\nabla \\cdot \\left(\\frac{\\nabla u}{|\\nabla u|}\\right)$$\n여기서 각 항의 의미는 다음과 같습니다:\n$u$: 진화하는 위상장 함수(evolving phase-field function). 정상 상태 해가 최종 분할을 정의합니다. $f$: 입력 이미지. $\\epsilon, \\lambda, \\mu$: 모델의 동작을 제어하는 양의 매개변수. $W(t) = (t^2 - 1)^2$: Lyapunov functional. $W’(u)$는 비선형 항입니다. $\\nabla \\cdot (\\nabla u / |\\nabla u|)$: **평균 곡률 항(Mean Curvature Term)**으로, 노이즈를 처리하고 경계를 평활화하도록 설계되었습니다. $u(f-c_1)^2 - (1-u)(f-c_2)^2$: 데이터 충실도 항(Data Fidelity Term). $c_1$과 $c_2$는 목표 영역 내부와 외부의 평균 강도입니다. 2. 엣지 검출기 (Edge Detector) 수정된 Cahn-Hilliard 방정식의 확산 항 $\\nabla \\cdot (g(\\nabla f)\\nabla u)$에 사용되는 엣지 검출기 함수 $g(|\\nabla f|)$는 다음과 같습니다 (Text, page 3):\n$$g(|\\nabla f|) = \\frac{1}{1 + \\beta|\\nabla f|^2}$$\n여기서 $\\beta \u003e 0$는 매개변수이며, 이 함수는 이미지 경계 근처에서 값이 감소하여 경계를 보존하는 역할을 합니다.\n3. 학습 목표 및 손실 함수 (Loss Function) 네트워크의 매개변수 $\\Theta$ (특히 $H(f)$의 매개변수)는 다음 목적 함수를 최소화하여 결정됩니다 (Eq. 7):\n$$\\min_{\\Theta} \\frac{1}{I} \\sum_{i=1}^{I} l(u(x, T; \\Theta, f_i), g_i)$$\n$I$: 훈련 이미지의 총 개수. $l(\\cdot, \\cdot)$: 손실 함수 (예: Hinge loss, Logistic loss, Binary Cross Entropy (BCE) loss). $u(x, T; \\Theta, f_i)$: 시간 $T$에서의 최종 분할 결과 (PDE의 정상 상태 해). $g_i$: 해당 이미지의 Ground Truth 마스크. Vanilla U-Net 비교 VM_TUNet은 기존 U-Net의 기본적인 인코더-디코더 형태를 차용하지만, 핵심적인 블록과 흐름을 변분법적 최적화 과정으로 대체하거나 수정했습니다.\n특징 Vanilla U-Net Robust VM_TUNet 핵심 구조 순수 CNN 기반 인코더-디코더. 변분 모델(PDE) 기반 하이브리드 아키텍처. 인코더 역할 대체 특징 추출 및 다운샘플링. F 모듈 (FSM 기반 $B_F$ 블록): 주파수 영역 전처리 및 노이즈 감소. 디코더 역할 대체 특징 복원 및 업샘플링. T 모듈 (TFPM 기반 $B_T$ 블록): 수정된 Cahn-Hilliard 방정식의 수치 해를 통한 반복적 변분 최적화. 경계 처리 Skip Connection을 통한 공간 정보 보존. 평균 곡률 항 및 엣지 검출기를 PDE에 명시적으로 통합하여 기하학적 경계 평활화 및 노이즈 강건성 확보. 학습 방식 데이터 기반 특징 학습. 데이터 기반 학습($H(f)$)과 물리 기반 최적화(T 모듈)의 결합. 4. 태그 제안 (Tags Suggestion) Image Segmentation Variational Model UNet Hybrid Architecture Cahn-Hilliard Equation Mean Curvature ",
  "wordCount" : "1462",
  "inLanguage": "en",
  "datePublished": "2025-12-08T00:00:00Z",
  "dateModified": "2025-12-08T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://hanwo-ol.github.io/Unet_master/posts/robust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Research Agent Knowledge Base",
    "logo": {
      "@type": "ImageObject",
      "url": "https://hanwo-ol.github.io/Unet_master/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://hanwo-ol.github.io/Unet_master/" accesskey="h" title="Research Agent Knowledge Base (Alt + H)">Research Agent Knowledge Base</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/categories/" title="categories">
                    <span>categories</span>
                </a>
            </li>
            <li>
                <a href="https://hanwo-ol.github.io/Unet_master/tags/" title="tags">
                    <span>tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://hanwo-ol.github.io/Unet_master/">Home</a>&nbsp;»&nbsp;<a href="https://hanwo-ol.github.io/Unet_master/posts/">Posts</a></div>
    <h1 class="post-title">
      Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation
    </h1>
    <div class="post-meta">&lt;span title=&#39;2025-12-08 00:00:00 &#43;0000 UTC&#39;&gt;December 8, 2025&lt;/span&gt;&amp;nbsp;·&amp;nbsp;7 min

</div>
  </header> 
  <div class="post-content"><h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.</p>
<h2 id="pdf-download">PDF Download<a hidden class="anchor" aria-hidden="true" href="#pdf-download">#</a></h2>
<p><a href="//172.22.138.185/Research_pdf/2512.07590v1.pdf">Local PDF View</a> | <a href="http://arxiv.org/abs/2512.07590v1">Arxiv Original</a></p>
<p>이 논문은 **&ldquo;ROBUST VARIATIONAL MODEL BASED TAILORED UNET: LEVERAGING EDGE DETECTOR AND MEAN CURVATURE FOR IMPROVED IMAGE SEGMENTATION&rdquo;**에 대한 상세 분석 리포트입니다.</p>
<hr>
<h2 id="1-요약-executive-summary">1. 요약 (Executive Summary)<a hidden class="anchor" aria-hidden="true" href="#1-요약-executive-summary">#</a></h2>
<p>본 논문은 경계가 흐릿하거나 파편화된 노이즈 이미지의 분할 문제를 해결하기 위해 **VM_TUNet (Variational Model Based Tailored UNet)**이라는 강건한 하이브리드 프레임워크를 제안합니다.</p>
<ul>
<li><strong>하이브리드 접근 방식:</strong> 변분법적 부분 미분 방정식(PDEs)의 해석 가능성 및 경계 평활화 이점을 딥러닝의 강력한 특징 표현 능력과 통합합니다.</li>
<li><strong>수정된 Cahn-Hilliard 방정식:</strong> 물리적 사전 지식(Physical Priors), 엣지 검출기($g(|\nabla f|)$), 그리고 평균 곡률 항($\nabla \cdot (\nabla u / |\nabla u|)$)을 통합하여 노이즈 환경에서 경계의 정확도와 안정성을 높입니다.</li>
<li><strong>협력적 모듈 아키텍처:</strong>
<ul>
<li><strong>F 모듈 (Frequency Domain Preprocessing):</strong> 효율적인 주파수 영역 전처리를 수행하여 국소 최솟값(local minima)을 피하고 후속 최적화를 위한 더 나은 초기 상태를 제공합니다.</li>
<li><strong>T 모듈 (Tailored Finite Point Method):</strong> 정확하고 안정적인 국소 계산을 보장하며, 알고리즘의 신뢰성을 뒷받침하는 조건부 수치 안정성 정리(Stability Estimate)를 제공합니다.</li>
</ul>
</li>
<li><strong>성과:</strong> 3가지 벤치마크 데이터셋(ECSSD, HKU-IS, DUT-OMRON)에서 광범위한 실험을 통해 순수 CNN 기반 모델 대비 경쟁적인 정량적 결과와 향상된 시각적 품질을 달성했습니다.</li>
<li><strong>효율성:</strong> 트랜스포머 기반 모델(Swin-UNet)과 유사한 성능을 달성하면서도 합리적인 계산 비용을 유지하여 성능과 효율성 간의 균형을 맞춥니다.</li>
</ul>
<hr>
<h2 id="2-7가지-핵심-질문-분석-key-analysis">2. 7가지 핵심 질문 분석 (Key Analysis)<a hidden class="anchor" aria-hidden="true" href="#2-7가지-핵심-질문-분석-key-analysis">#</a></h2>
<h3 id="1-what-is-new-in-the-work-기존-연구와의-차별점">1) What is new in the work? (기존 연구와의 차별점)<a hidden class="anchor" aria-hidden="true" href="#1-what-is-new-in-the-work-기존-연구와의-차별점">#</a></h3>
<p>본 연구는 변분법적 PDE와 딥러닝을 결합한 하이브리드 프레임워크인 VM_TUNet을 제안합니다. 가장 큰 차별점은 <strong>수정된 Cahn-Hilliard 방정식</strong>에 엣지 검출기($g(|\nabla f|)$)와 평균 곡률 항($\nabla \cdot (\nabla u / |\nabla u|)$)과 같은 물리적 사전 지식을 명시적으로 통합했다는 점입니다. 또한, 아키텍처를 효율적인 주파수 영역 전처리(F 모듈)와 안정적인 국소 계산(T 모듈)을 담당하는 두 가지 협력 모듈로 분리하여, 기존의 변분 모델이 겪던 계산 비용 문제와 딥러닝 모델이 노이즈 환경에서 겪는 경계 품질 저하 문제를 동시에 해결하고자 했습니다.</p>
<h3 id="2-why-is-the-work-important-연구의-중요성">2) Why is the work important? (연구의 중요성)<a hidden class="anchor" aria-hidden="true" href="#2-why-is-the-work-important-연구의-중요성">#</a></h3>
<p>이 연구는 노이즈가 심하거나 경계가 모호한 이미지 분할이라는 실질적인 난제를 해결하는 데 중요합니다. 기존의 딥러닝 모델은 강력한 표현 능력을 가졌지만, 노이즈가 많거나 학습 데이터가 제한적일 때 경계의 정확도와 해석 가능성이 떨어지는 한계가 있었습니다. VM_TUNet은 변분법의 **해석 가능성(Interpretability)**과 <strong>경계 평활화(Boundary Smoothness)</strong> 이점을 딥러닝에 통합함으로써, 노이즈에 강건하며 기하학적으로 일관된 분할 결과를 제공합니다. 특히 T 모듈에 대한 조건부 수치 안정성 정리를 제공하여 알고리즘의 신뢰성을 이론적으로 뒷받침합니다.</p>
<h3 id="3-what-is-the-literature-gap-기존-연구의-한계점">3) What is the literature gap? (기존 연구의 한계점)<a hidden class="anchor" aria-hidden="true" href="#3-what-is-the-literature-gap-기존-연구의-한계점">#</a></h3>
<p>기존의 순수 변분 모델은 높은 계산 비용 때문에 대규모 또는 노이즈가 많은 이미지에 실시간으로 적용하기 어려웠으며, 초기화에 민감하고 국소 최솟값에 빠지기 쉬웠습니다. 반면, UNet이나 Swin-UNet 같은 딥러닝 모델은 노이즈가 심한 이미지에서 때때로 파편화되거나 톱니 모양의 경계를 생성하는 등 비정상적인 결과를 초래했습니다. 특히, 기존 하이브리드 모델들조차 저차 PDE에 해당하는 에너지 함수를 사용하기 때문에 미묘한 경계를 보존하는 데 어려움을 겪었습니다.</p>
<h3 id="4-how-is-the-gap-filled-해결-방안">4) How is the gap filled? (해결 방안)<a hidden class="anchor" aria-hidden="true" href="#4-how-is-the-gap-filled-해결-방안">#</a></h3>
<p>본 논문은 F 모듈과 T 모듈을 통해 이 간극을 메웁니다. F 모듈은 **Fourier Spectral Method (FSM)**를 기반으로 주파수 영역에서 효율적인 전처리를 수행하여 노이즈를 줄이고 최적화 초기 상태를 개선합니다. T 모듈은 **Tailored Finite Point Method (TFPM)**를 구현하여 수정된 Cahn-Hilliard 방정식을 반복적으로 풀며 정확하고 안정적인 국소 계산을 수행합니다. 이 변분법적 최적화 과정은 딥러닝 네트워크 내에 통합되어, 네트워크가 데이터 충실도 항 $H(f)$를 학습하도록 함으로써 수동적인 매개변수 튜닝 없이도 노이즈에 강건한 경계 평활화 효과를 얻습니다.</p>
<h3 id="5-what-is-achieved-with-the-new-method-달성한-성과">5) What is achieved with the new method? (달성한 성과)<a hidden class="anchor" aria-hidden="true" href="#5-what-is-achieved-with-the-new-method-달성한-성과">#</a></h3>
<p>VM_TUNet은 노이즈 환경($\sigma=0.5$)에서 기존 CNN 및 하이브리드 모델 대비 우수한 성능을 달성했습니다 (Table 2 참조).</p>
<table>
<thead>
<tr>
<th style="text-align:left">모델</th>
<th style="text-align:left">ECSSD Dice (↑)</th>
<th style="text-align:left">HKU-IS HD95 (↓)</th>
<th style="text-align:left">DUT-OMRON Dice (↑)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">UNet</td>
<td style="text-align:left">$0.873 \pm 0.004$</td>
<td style="text-align:left">$1.602 \pm 0.012$</td>
<td style="text-align:left">$0.868 \pm 0.003$</td>
</tr>
<tr>
<td style="text-align:left">Swin-UNet</td>
<td style="text-align:left">$0.910 \pm 0.002$</td>
<td style="text-align:left">$1.001 \pm 0.007$</td>
<td style="text-align:left">$0.905 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align:left">DN</td>
<td style="text-align:left">$0.896 \pm 0.002$</td>
<td style="text-align:left">$1.287 \pm 0.010$</td>
<td style="text-align:left">$0.885 \pm 0.001$</td>
</tr>
<tr>
<td style="text-align:left"><strong>Ours</strong></td>
<td style="text-align:left"><strong>$0.919 \pm 0.003$</strong></td>
<td style="text-align:left"><strong>$0.989 \pm 0.004$</strong></td>
<td style="text-align:left">$0.902 \pm 0.001$</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>정량적 성과:</strong> ECSSD 및 HKU-IS에서 가장 높은 Dice 점수와 가장 낮은 HD95(경계 정확도)를 기록하여, 노이즈 조건 하에서 향상된 영역 일치도와 경계 안정성을 입증했습니다. 특히 ECSSD Dice 점수는 Swin-UNet($0.910$)보다 높은 **$0.919$**를 달성했습니다.</li>
<li><strong>효율성 (Table 3):</strong> 에포크당 실행 시간은 UNet(5.54s)이나 UNet++(7.36s)보다 길지만, 트랜스포머 기반 Swin-UNet(10.87s) 및 하이브리드 DN(11.05s)과 비교했을 때 합리적인 수준인 <strong>23.46s</strong>를 기록했습니다. 이는 도입된 모듈이 성능 향상에 기여하면서도 계산 효율성을 크게 저해하지 않음을 시사합니다.</li>
</ul>
<h3 id="6-what-data-are-used-사용-데이터셋">6) What data are used? (사용 데이터셋)<a hidden class="anchor" aria-hidden="true" href="#6-what-data-are-used-사용-데이터셋">#</a></h3>
<p>세 가지 벤치마크 데이터셋이 사용되었으며, 모든 이미지에는 다양한 표준 편차($\sigma$)를 가진 영평균 가우시안 노이즈(zero-mean Gaussian noise)가 인위적으로 추가되었습니다.</p>
<ol>
<li><strong>ECSSD:</strong> 1000개의 의미론적으로 주석이 달린 이미지로, 복잡한 배경과 픽셀 단위 수동 주석이 특징입니다. (시각적 현저성(Saliency) 도메인)</li>
<li><strong>HKU-IS:</strong> 4447개의 도전적인 이미지로, 낮은 대비 또는 다중 현저 객체를 포함합니다. (시각적 현저성 도메인)</li>
<li><strong>DUT-OMRON:</strong> 5168개의 고품질 자연 이미지로, 다양하고 복잡한 배경에 하나 이상의 현저 객체를 포함합니다.</li>
</ol>
<h3 id="7-what-are-the-limitations-저자가-언급한-한계점">7) What are the limitations? (저자가 언급한 한계점)<a hidden class="anchor" aria-hidden="true" href="#7-what-are-the-limitations-저자가-언급한-한계점">#</a></h3>
<p>저자는 다음과 같은 한계점을 언급했습니다.</p>
<ol>
<li><strong>성능 개선의 정도:</strong> 엣지 선명도, 디테일 유지 및 전반적인 분할 정확도 측면에서 기존 CNN 기반 접근 방식 대비 <strong>완만한(modest)</strong> 개선을 달성했으며, 트랜스포머 기반 기술과 비교했을 때는 비슷한 수준입니다.</li>
<li><strong>계산 비용:</strong> 순수 CNN 모델(UNet, UNet++)에 비해 계산 요구 사항이 높습니다.</li>
<li><strong>이론적 이해 및 확장:</strong> 향후 연구에서는 인스턴스 분할(instance segmentation) 및 3D 의료 영상 처리와 같은 더 도전적인 작업으로 모델을 확장하고, 모델의 광범위한 속성에 대한 보다 체계적인 이론적 이해를 개발해야 합니다.</li>
</ol>
<hr>
<h2 id="3-아키텍처-및-방법론-architecture--methodology">3. 아키텍처 및 방법론 (Architecture &amp; Methodology)<a hidden class="anchor" aria-hidden="true" href="#3-아키텍처-및-방법론-architecture--methodology">#</a></h2>
<h3 id="figure-분석-robust-vm_tunet-아키텍처-figure-1">Figure 분석: Robust VM_TUNet 아키텍처 (Figure 1)<a hidden class="anchor" aria-hidden="true" href="#figure-분석-robust-vm_tunet-아키텍처-figure-1">#</a></h3>
<p>VM_TUNet은 기존 U-Net의 인코더-디코더 구조를 변분법적 최적화 단계와 딥러닝 특징 학습을 결합한 두 가지 핵심 모듈(F 모듈, T 모듈)로 대체한 하이브리드 구조입니다.</p>
<ul>
<li><strong>전체 흐름 (a):</strong>
<ol>
<li>입력 이미지 $f$가 <strong>F 모듈</strong>을 통과합니다.</li>
<li>F 모듈의 출력은 <strong>Sigmoid</strong> 함수를 거쳐 T 모듈의 입력으로 사용됩니다.</li>
<li><strong>T 모듈</strong>은 F 모듈의 출력과 <strong>$H(f)$</strong> (학습된 데이터 충실도 항)를 입력으로 받아 변분법적 최적화를 수행합니다.</li>
<li>T 모듈의 출력 $u_T$는 최종적으로 <strong>$W * u_T + b$</strong> (컨볼루션 레이어와 바이어스)를 거쳐 Sigmoid 함수를 통해 최종 분할 출력(output)을 생성합니다.</li>
</ol>
</li>
<li><strong>F 모듈 (b):</strong> <strong>FSM (Fourier Spectral Method)</strong> 블록($B_F$)의 시퀀스로 구성되어 있으며, 주파수 영역에서 효율적인 전처리를 담당합니다.</li>
<li><strong>T 모듈 (c):</strong> <strong>TFPM (Tailored Finite Point Method)</strong> 블록($B_T$)의 시퀀스로 구현되며, 수정된 Cahn-Hilliard 방정식의 반복적인 수치 해를 계산하여 정확하고 안정적인 국소 계산을 수행합니다.</li>
</ul>
<h3 id="수식-상세">수식 상세<a hidden class="anchor" aria-hidden="true" href="#수식-상세">#</a></h3>
<h4 id="1-수정된-cahn-hilliard-방정식-modified-cahn-hilliard-equation">1. 수정된 Cahn-Hilliard 방정식 (Modified Cahn-Hilliard Equation)<a hidden class="anchor" aria-hidden="true" href="#1-수정된-cahn-hilliard-방정식-modified-cahn-hilliard-equation">#</a></h4>
<p>본 논문에서 제안하는 노이즈 이미지 분할을 위한 수정된 Cahn-Hilliard 방정식은 다음과 같습니다 (Eq. 1):</p>
<p>$$\frac{\partial u}{\partial t} = -\Delta\left[\epsilon \cdot (\nabla u) - \frac{2}{\epsilon} W&rsquo;(u)\right] - \lambda\left[u(f-c_1)^2 - (1-u)(f-c_2)^2\right] + \mu\nabla \cdot \left(\frac{\nabla u}{|\nabla u|}\right)$$</p>
<p>이는 다음의 형태로 변환될 수 있습니다 (Eq. 2):</p>
<p>$$\frac{\partial u}{\partial t} = -\Delta\left(\epsilon\Delta u - \frac{2}{\epsilon} W&rsquo;(u)\right) - \lambda\left[u(f-c_1)^2 - (1-u)(f-c_2)^2\right] + \mu\nabla \cdot \left(\frac{\nabla u}{|\nabla u|}\right)$$</p>
<p>여기서 각 항의 의미는 다음과 같습니다:</p>
<ul>
<li>$u$: 진화하는 위상장 함수(evolving phase-field function). 정상 상태 해가 최종 분할을 정의합니다.</li>
<li>$f$: 입력 이미지.</li>
<li>$\epsilon, \lambda, \mu$: 모델의 동작을 제어하는 양의 매개변수.</li>
<li>$W(t) = (t^2 - 1)^2$: Lyapunov functional. $W&rsquo;(u)$는 비선형 항입니다.</li>
<li>$\nabla \cdot (\nabla u / |\nabla u|)$: **평균 곡률 항(Mean Curvature Term)**으로, 노이즈를 처리하고 경계를 평활화하도록 설계되었습니다.</li>
<li>$u(f-c_1)^2 - (1-u)(f-c_2)^2$: <strong>데이터 충실도 항(Data Fidelity Term)</strong>. $c_1$과 $c_2$는 목표 영역 내부와 외부의 평균 강도입니다.</li>
</ul>
<h4 id="2-엣지-검출기-edge-detector">2. 엣지 검출기 (Edge Detector)<a hidden class="anchor" aria-hidden="true" href="#2-엣지-검출기-edge-detector">#</a></h4>
<p>수정된 Cahn-Hilliard 방정식의 확산 항 $\nabla \cdot (g(\nabla f)\nabla u)$에 사용되는 엣지 검출기 함수 $g(|\nabla f|)$는 다음과 같습니다 (Text, page 3):</p>
<p>$$g(|\nabla f|) = \frac{1}{1 + \beta|\nabla f|^2}$$</p>
<p>여기서 $\beta &gt; 0$는 매개변수이며, 이 함수는 이미지 경계 근처에서 값이 감소하여 경계를 보존하는 역할을 합니다.</p>
<h4 id="3-학습-목표-및-손실-함수-loss-function">3. 학습 목표 및 손실 함수 (Loss Function)<a hidden class="anchor" aria-hidden="true" href="#3-학습-목표-및-손실-함수-loss-function">#</a></h4>
<p>네트워크의 매개변수 $\Theta$ (특히 $H(f)$의 매개변수)는 다음 목적 함수를 최소화하여 결정됩니다 (Eq. 7):</p>
<p>$$\min_{\Theta} \frac{1}{I} \sum_{i=1}^{I} l(u(x, T; \Theta, f_i), g_i)$$</p>
<ul>
<li>$I$: 훈련 이미지의 총 개수.</li>
<li>$l(\cdot, \cdot)$: 손실 함수 (예: Hinge loss, Logistic loss, Binary Cross Entropy (BCE) loss).</li>
<li>$u(x, T; \Theta, f_i)$: 시간 $T$에서의 최종 분할 결과 (PDE의 정상 상태 해).</li>
<li>$g_i$: 해당 이미지의 Ground Truth 마스크.</li>
</ul>
<h3 id="vanilla-u-net-비교">Vanilla U-Net 비교<a hidden class="anchor" aria-hidden="true" href="#vanilla-u-net-비교">#</a></h3>
<p>VM_TUNet은 기존 U-Net의 기본적인 인코더-디코더 형태를 차용하지만, 핵심적인 블록과 흐름을 변분법적 최적화 과정으로 대체하거나 수정했습니다.</p>
<table>
<thead>
<tr>
<th style="text-align:left">특징</th>
<th style="text-align:left">Vanilla U-Net</th>
<th style="text-align:left">Robust VM_TUNet</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>핵심 구조</strong></td>
<td style="text-align:left">순수 CNN 기반 인코더-디코더.</td>
<td style="text-align:left">변분 모델(PDE) 기반 하이브리드 아키텍처.</td>
</tr>
<tr>
<td style="text-align:left"><strong>인코더 역할 대체</strong></td>
<td style="text-align:left">특징 추출 및 다운샘플링.</td>
<td style="text-align:left"><strong>F 모듈 (FSM 기반 $B_F$ 블록):</strong> 주파수 영역 전처리 및 노이즈 감소.</td>
</tr>
<tr>
<td style="text-align:left"><strong>디코더 역할 대체</strong></td>
<td style="text-align:left">특징 복원 및 업샘플링.</td>
<td style="text-align:left"><strong>T 모듈 (TFPM 기반 $B_T$ 블록):</strong> 수정된 Cahn-Hilliard 방정식의 수치 해를 통한 반복적 변분 최적화.</td>
</tr>
<tr>
<td style="text-align:left"><strong>경계 처리</strong></td>
<td style="text-align:left">Skip Connection을 통한 공간 정보 보존.</td>
<td style="text-align:left"><strong>평균 곡률 항</strong> 및 <strong>엣지 검출기</strong>를 PDE에 명시적으로 통합하여 기하학적 경계 평활화 및 노이즈 강건성 확보.</td>
</tr>
<tr>
<td style="text-align:left"><strong>학습 방식</strong></td>
<td style="text-align:left">데이터 기반 특징 학습.</td>
<td style="text-align:left">데이터 기반 학습($H(f)$)과 물리 기반 최적화(T 모듈)의 결합.</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="4-태그-제안-tags-suggestion">4. 태그 제안 (Tags Suggestion)<a hidden class="anchor" aria-hidden="true" href="#4-태그-제안-tags-suggestion">#</a></h2>
<ol>
<li>Image Segmentation</li>
<li>Variational Model</li>
<li>UNet Hybrid Architecture</li>
<li>Cahn-Hilliard Equation</li>
<li>Mean Curvature</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/image-segmentation/">Image Segmentation</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/variational-model/">Variational Model</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/unet-hybrid-architecture/">UNet Hybrid Architecture</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/cahn-hilliard-equation/">Cahn-Hilliard Equation</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/mean-curvature/">Mean Curvature</a></li>
      <li><a href="https://hanwo-ol.github.io/Unet_master/tags/u-net/">U-Net</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://hanwo-ol.github.io/Unet_master/posts/clinical-interpretability-of-deep-learning-segmentation-through-shapley-derived-agreement-and-uncertainty-metrics/">
    <span class="title">« Prev</span>
    <br>
    <span>Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics</span>
  </a>
  <a class="next" href="https://hanwo-ol.github.io/Unet_master/posts/daunet-a-lightweight-unet-variant-with-deformable-convolutions-and-parameter-free-attention-for-medical-image-segmentation/">
    <span class="title">Next »</span>
    <br>
    <span>DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation</span>
  </a>
</nav>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on twitter"
        href="https://twitter.com/intent/tweet/?text=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f&amp;hashtags=ImageSegmentation%2cVariationalModel%2cUNetHybridArchitecture%2cCahn-HilliardEquation%2cMeanCurvature%2cU-Net">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f&amp;title=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation&amp;summary=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation&amp;source=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f&title=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on whatsapp"
        href="https://api.whatsapp.com/send?text=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation%20-%20https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation on telegram"
        href="https://telegram.me/share/url?text=Robust%20Variational%20Model%20Based%20Tailored%20UNet%3a%20Leveraging%20Edge%20Detector%20and%20Mean%20Curvature%20for%20Improved%20Image%20Segmentation&amp;url=https%3a%2f%2fhanwo-ol.github.io%2fUnet_master%2fposts%2frobust-variational-model-based-tailored-unet-leveraging-edge-detector-and-mean-curvature-for-improved-image-segmentation%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://hanwo-ol.github.io/Unet_master/">Research Agent Knowledge Base</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
